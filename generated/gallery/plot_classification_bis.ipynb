{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Multi-Selective Classification\n\nThis example shows how to use the `MultiSelectiveClassification` and `RiskController`\nclasses to perform multi-selective classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport sys\nfrom typing import List\n\nbasedir = os.path.abspath(os.path.join(os.path.curdir, \"..\"))\nsys.path.append(basedir)\nbasedir = os.path.abspath(os.path.join(os.path.curdir, \".\"))\nsys.path.append(basedir)\n\nimport numpy as np\nfrom utils.data import get_data_classification\nfrom utils.model import get_model_classification\n\nfrom mlrisko import RiskController\nfrom mlrisko.decision import MultiLabelDecision\nfrom mlrisko.decision.base import BaseDecision\nfrom mlrisko.parameter import BaseParameterSpace\nfrom mlrisko.plot import plot_p_values, plot_risk_curve\nfrom mlrisko.risk import (\n    BaseRisk,\n    CoverageRisk,\n    FalseDiscoveryRisk,\n    NonUniqueCandidateRisk,\n)\n\nrandom_state = 42\nnp.random.seed(random_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we load the data and train a model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_train, X_cal, X_test, y_train, y_cal, y_test = get_data_classification(random_state)\nclf = get_model_classification(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can plot the data and the decision boundary.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# plot_classification(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, we define the decision, the risks, and the parameter space.\n\nWe use the `MultiSelectiveClassification` decision, the `AccuracyRisk`,\n`AbstentionRisk` and `CoverageRisk` risks.\n\n- The `MultiSelectiveClassification` decision is a selective classification decision.\nIn practice, it is a classification model with a threshold on any class confidence\nscore. If the class confidence score is above the threshold, the class is put in\nthe prediction set, otherwise it is not. The threshold is the parameter to tune.\n- The `CoverageRisk` risk is the coverage risk. It is the ratio of predictions\ncontaining the true label. We want the coverage to be controlled at a given level\n(here 0.5, TODO: report the target performance instead of the target risk).\n- The `AbstentionRisk` risk is the ratio prediction risk. It is the ratio of accepted\npredictions. We want the ratio of predictions to be controlled at a given level\n(here 0.3, TODO: report the target performance instead of the target risk).\n\nWe want to find the valid thresholds that control the risks at the given levels\nwith a confidence level (here 0.9, TODO: report the confidence level instead of\nthe delta).\n\nAmong the valid thresholds, we want to find the one that maximizes the `AccuracyRisk`\nrisk (beause it is the first risk in the list of risks and `control_method=\"lmin\"`).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "decision: BaseDecision = MultiLabelDecision(estimator=clf)\n\nrisks: List[BaseRisk] = [\n    CoverageRisk(0.2),\n    FalseDiscoveryRisk(0.2),\n    NonUniqueCandidateRisk(0.4),\n]\nparams: BaseParameterSpace = {\"threshold\": np.arange(-1.0, 5.0, 0.1)}\n\ncontroller = RiskController(\n    decision=decision,\n    risks=risks,\n    params=params,\n    delta=0.1,\n    control_method=\"rmin\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we fit the model and plot the results. In practice, this function will be\nused to find the valid thresholds that control the risks at the given levels with\na confidence level given by the data.\n\nA summary of the results is printed that contains the optimal threshold and the\ncorresponding risks.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "controller.fit(X_cal, y_cal)\ncontroller.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can plot the risk curves for each risk.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_risk_curve(controller)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also plot the p-values for each multiple tests (parameter space).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_p_values(controller)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we can use the optimal threshold to predict on the test set and compute\nthe risks. The risks are computed on the test set and converted to performance\nmetrics. We can check that the risks are controlled at the given levels.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y_pred = controller.predict(X_test)\nfor risk in risks:\n    ratio = risk.convert_to_performance(np.nanmean(risk.compute(y_pred, y_test)))\n    print(f\"{risk.name}: {ratio:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}