{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Selective (Binary) Classification for Human-AI Collaboration\n\nThis example shows how to use the `SelectiveClassification` and `MapieRiskControl` classes to perform selective classification.\n\nIn which use case? When you want to assist a human decision-maker with a machine learning model.\n\nThe goal is to provide a model that can make predictions only when it is confident enough to do so.\nWe will identify three different scenarios:\n\n- The model is confident enough to make a positive feedback (i.e., the model predicts a positive class and is confident enough to do so).\n- The model is confident enough to make a negative feedback (i.e., the model predicts a negative class and is confident enough to do so).\n- The model is not confident enough to make a feedback (i.e., the model abstains from making a prediction).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport sys\nimport warnings\n\nfrom risk_control.decision.base import BaseDecision\nfrom risk_control.parameter import BaseParameterSpace\n\nbasedir = os.path.abspath(os.path.join(os.path.curdir, \"..\"))\nsys.path.append(basedir)\nbasedir = os.path.abspath(os.path.join(os.path.curdir, \".\"))\nsys.path.append(basedir)\n\nimport numpy as np\nfrom risk_control import MapieRiskControl\nfrom risk_control.decision import SelectiveClassification\nfrom risk_control.plot import plot_p_values, plot_risk_curve\nfrom risk_control.risk import (\n    AbstentionRisk,\n    AccuracyRisk,\n    BaseRisk,\n    CoverageRisk,\n    FalseDiscoveryRisk,\n)\n\nrandom_state = 42\nnp.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we load the data and train a model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\ndata = load_breast_cancer()\n\nX_train, X_test, y_train, y_test = train_test_split(\n    data.data, data.target, test_size=0.33, random_state=random_state\n)\nX_calib, X_test, y_calib, y_test = train_test_split(\n    X_test, y_test, test_size=0.5, random_state=random_state\n)\n\n# Flip randomly 10% of the labels\ny_train = np.where(\n    np.random.rand(y_train.shape[0]) < 0.2,\n    1 - y_train,\n    y_train,\n)\n\n# model = RandomForestClassifier\nwith warnings.catch_warnings(action=\"ignore\"):\n    model = LogisticRegression(\n        penalty=\"l1\", solver=\"liblinear\", random_state=random_state\n    )\n    model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "At this step, what are the performance of the model on the test set?\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n\ny_pred = model.predict(X_test)\nscore = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy on the test set: {score:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We propose to compute the confidence interval of the performance of the model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from scipy.stats import norm\n\n\ndef confidence_interval(array, alpha=0.05):\n    n = len(array)\n    mean = np.mean(array)\n    var = np.var(array)\n    se = np.sqrt(var / n)\n    z = norm.ppf(1 - alpha / 2)\n    return mean - z * se, mean + z * se\n\n\narray = np.array(y_pred == y_test)\nscore_ci = confidence_interval(array, alpha=0.1)\nprint(f\"Confidence interval of the accuracy: {score_ci[0]:.2f} - {score_ci[1]:.2f}\")\n\nfrom risk_control.abstention import _abs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will define a new decision rule that will be used to make decisions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from risk_control.decision import SelectiveClassification\nfrom risk_control.decision.classification import BaseClassificationDecision\nfrom sklearn.base import BaseEstimator\n\n\nclass SelectiveClassification(BaseClassificationDecision):\n    def __init__(\n        self, estimator: BaseEstimator, *, pmin: float = 0.0, pmax: float = 0.0, **kwargs\n    ) -> None:\n        super().__init__(estimator=estimator, **kwargs)\n        self.pmin = pmin\n        self.pmax = pmax\n\n    def make_decision(self, y_output: np.ndarray) -> np.ndarray:\n        \"\"\"Make a decision based on the output of the model.\"\"\"\n        if self.predict_mode == \"score\":\n            (n_samples,) = y_output.shape\n            y_min = np.zeros_like(y_output)\n            y_max = np.ones_like(y_output)\n            y_empty = np.empty_like(y_output) * (_abs)\n            y_post = np.where(\n                y_output <= self.pmin,\n                y_min,\n                np.where(y_output >= self.pmax, y_max, y_empty),\n            )\n        else:\n            (n_samples, n_features) = y_output.shape\n            y_min = np.zeros_like(n_samples)\n            y_max = np.ones_like(n_samples)\n            y_empty = np.empty_like(n_samples) * (_abs)\n            y_post = np.where(\n                y_output[..., 0] <= self.pmin,\n                y_min,\n                np.where(y_output[..., 1] >= self.pmax, y_max, y_empty),\n            )\n\n        return y_post"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, we define the decision, the risks, and the parameter space.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "decision: BaseDecision = SelectiveClassification(\n    estimator=model,\n    predict_mode=\"score\",\n)\nrisks: list[BaseRisk] = [FalseDiscoveryRisk(0.1), AbstentionRisk(0.5)]\nparams: BaseParameterSpace = {\n    \"pmax\": np.linspace(-2.0, 2.0, 21),\n    \"pmin\": np.linspace(-2.0, 2.0, 21),\n    # \"pmax\": np.linspace(.0, 1., 51),\n    # \"pmin\": np.linspace(.0, 1., 51),\n}\n\n\ndef lambda_to_select(l_value):\n    pmin = l_value[\"pmin\"]\n    pmax = l_value[\"pmax\"]\n    return pmin <= pmax\n\n\nclf_mapie = MapieRiskControl(\n    decision=decision,\n    risks=risks,\n    params=params,\n    delta=0.1,\n    control_method=\"rmin\",\n    lambda_to_select=lambda_to_select,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we fit the model and plot the results. In practice, this function will be used to find the valid\nthresholds that control the risks at the given levels with a confidence level given by the data.\n\nA summary of the results is printed that contains the optimal threshold and the corresponding risks.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "clf_mapie.fit(X_calib, y_calib)\nclf_mapie.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can plot the risk curves for each risk.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_risk_curve(clf_mapie)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also plot the p-values for each multiple tests (parameter space).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_p_values(clf_mapie)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we can use the optimal threshold to predict on the test set and compute the risks.\nThe risks are computed on the test set and converted to performance metrics.\nWe can check that the risks are controlled at the given levels.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y_pred = clf_mapie.predict(X_test)\nfor risk in risks:\n    risk_array = risk.compute(y_pred, y_test)\n    ratio = risk.convert_to_performance(np.nanmean(risk_array))\n    risk_array = risk_array[~np.isnan(risk_array)]\n\n    score_ci = confidence_interval(risk_array, alpha=0.1)\n    smin = risk.convert_to_performance(score_ci[1])\n    smax = risk.convert_to_performance(score_ci[0])\n    print(f\"{risk.name}: {ratio:.2f} | {smin:.2f} - {smax:.2f} \")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}