{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Risk Control Project","text":"<p>This project focuses on developing and implementing risk control mechanisms for predictive algorithms based on the paper \"Learn then test: Calibrating predictive algorithms to achieve risk control\" by Angelopoulos et al. (2025). The primary goal is to ensure that the algorithms perform reliably and maintain a controlled level of risk.</p>"},{"location":"#installation","title":"Installation","text":"<p>To install the necessary dependencies, run:</p> <pre><code>uv sync\nuv pip install -e .\n</code></pre> <p>For development purposes, you can install the development dependencies with: <pre><code>uv sync --all-groups\n</code></pre></p>"},{"location":"#running-the-example","title":"Running the Example","text":"<p>To run the example, execute the following command:</p> <pre><code>uv run python examples/plot_regression.py\nuv run python examples/plot_classification.py\nuv run python examples/plot_classification_bis.py\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<p>For detailed documentation, refer to the docs.</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License.</p>"},{"location":"#references","title":"References","text":"<p>Angelopoulos, A. N., Bates, S., Cand\u00e8s, E. J., Jordan, M. I., &amp; Lei, L. (2025). Learn then test: Calibrating predictive algorithms to achieve risk control. The Annals of Applied Statistics, 19(2), 1641-1662.</p>"},{"location":"api/parameter/","title":"Parameter Module","text":""},{"location":"api/parameter/#parameter","title":"Parameter Module","text":"<p>Attributes:</p> Name Type Description <code>BaseParameterSpace</code>"},{"location":"api/parameter/#parameter.BaseParameterSpace","title":"BaseParameterSpace  <code>module-attribute</code>","text":"<pre><code>BaseParameterSpace = dict[str, Any]\n</code></pre>"},{"location":"api/risk/","title":"Risk Based","text":""},{"location":"api/risk/#risk","title":"Risk Module","text":"<p>Classes:</p> Name Description <code>BaseRisk</code> <p>Abstract base class for computing risks.</p> <code>MSERisk</code> <p>A class used to compute risks based on Mean Squared Error (MSE).</p> <code>AccuracyRisk</code> <p>A class used to compute risks based on the accuracy of predictions.</p> <code>AccuracyRiskV2</code> <p>A class used to compute risks based on the accuracy of predictions.</p> <code>CoverageRisk</code> <p>A class used to compute risks based on the coverage of prediction sets.</p> <code>RatioPredictionRisk</code> <p>A class used to compute risks based on the ratio human/machine predictions.</p>"},{"location":"api/risk/#risk.BaseRisk","title":"BaseRisk","text":"<pre><code>BaseRisk(acceptable_risk)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Abstract base class for computing risks.</p> <p>This class provides methods for computing risks based on predictions made by an estimator or directly from predictions and true values.</p> <p>Parameters:</p> Name Type Description Default <code>acceptable_risk</code> <code>float</code> <p>The acceptable risk value.</p> required <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The name of the risk function.</p> <code>greater_is_better</code> <code>bool</code> <p>Whether a higher risk value is better.</p> <code>acceptable_risk</code> <code>float</code> <p>The acceptable risk value.</p> <p>Methods:</p> Name Description <code>convert_to_performance</code> <p>Convert risk to performance measure.</p> <code>compute</code> <p>Compute the risks based on predictions and true values.</p> Source code in <code>risk_control/risk.py</code> <pre><code>def __init__(self, acceptable_risk: float):\n    self.acceptable_risk = acceptable_risk\n</code></pre>"},{"location":"api/risk/#risk.BaseRisk.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name\n</code></pre>"},{"location":"api/risk/#risk.BaseRisk.greater_is_better","title":"greater_is_better  <code>instance-attribute</code>","text":"<pre><code>greater_is_better\n</code></pre>"},{"location":"api/risk/#risk.BaseRisk.acceptable_risk","title":"acceptable_risk  <code>instance-attribute</code>","text":"<pre><code>acceptable_risk = acceptable_risk\n</code></pre>"},{"location":"api/risk/#risk.BaseRisk.convert_to_performance","title":"convert_to_performance","text":"<pre><code>convert_to_performance(x)\n</code></pre> <p>Convert risk to performance measure. If the object is a risk, the performance measure is the risk.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>float</code> <p>The risk value.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The performance measure.</p> Source code in <code>risk_control/risk.py</code> <pre><code>def convert_to_performance(self, x: float) -&gt; float:\n    \"\"\"\n    Convert risk to performance measure.\n    If the object is a risk, the performance measure is the risk.\n\n    Parameters\n    ----------\n    x : float\n        The risk value.\n\n    Returns\n    -------\n    float\n        The performance measure.\n    \"\"\"\n    return x\n</code></pre>"},{"location":"api/risk/#risk.BaseRisk._compute_from_estimator","title":"_compute_from_estimator","text":"<pre><code>_compute_from_estimator(estimator, X, y_true, **kwargs)\n</code></pre> <p>Compute the risk based on predictions made by an estimator.</p> <p>Parameters:</p> Name Type Description Default <code>estimator</code> <code>BaseEstimator</code> <p>The estimator used to make predictions. Need to implement <code>predict</code> method.</p> required <code>X</code> <code>ndarray</code> <p>The input samples.</p> required <code>y_true</code> <code>ndarray</code> <p>The true values.</p> required <code>**kwargs</code> <code>dict</code> <p>Additional keyword arguments (used in <code>compute</code>).</p> <code>{}</code> <p>Returns:</p> Type Description <code>float</code> <p>The computed risk.</p> Source code in <code>risk_control/risk.py</code> <pre><code>def _compute_from_estimator(\n    self, estimator: BaseEstimator, X: np.ndarray, y_true: np.ndarray, **kwargs\n) -&gt; float:\n    \"\"\"\n    Compute the risk based on predictions made by an estimator.\n\n    Parameters\n    ----------\n    estimator : BaseEstimator\n        The estimator used to make predictions.\n        Need to implement `predict` method.\n    X : np.ndarray\n        The input samples.\n    y_true : np.ndarray\n        The true values.\n    **kwargs : dict\n        Additional keyword arguments (used in [`compute`][risk.BaseRisk.compute]).\n\n    Returns\n    -------\n    float\n        The computed risk.\n    \"\"\"\n    y_pred = estimator.predict(X)\n    return self._compute_from_predictions(y_pred, y_true, **kwargs)\n</code></pre>"},{"location":"api/risk/#risk.BaseRisk._compute_from_predictions","title":"_compute_from_predictions","text":"<pre><code>_compute_from_predictions(y_pred, y_true, **kwargs)\n</code></pre> <p>Compute the risk based on predictions and true values.</p> <p>Parameters:</p> Name Type Description Default <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>y_true</code> <code>ndarray</code> <p>The true values.</p> required <code>**kwargs</code> <code>dict</code> <p>Additional keyword arguments (used in <code>compute</code>).</p> <code>{}</code> <p>Returns:</p> Type Description <code>float</code> <p>The computed risk.</p> Source code in <code>risk_control/risk.py</code> <pre><code>def _compute_from_predictions(\n    self, y_pred: np.ndarray, y_true: np.ndarray, **kwargs\n) -&gt; float:\n    \"\"\"\n    Compute the risk based on predictions and true values.\n\n    Parameters\n    ----------\n    y_pred : np.ndarray\n        The predicted values.\n    y_true : np.ndarray\n        The true values.\n    **kwargs : dict\n        Additional keyword arguments (used in [`compute`][risk.BaseRisk.compute]).\n\n    Returns\n    -------\n    float\n        The computed risk.\n    \"\"\"\n    return self._compute_mean(y_pred, y_true, **kwargs)\n</code></pre>"},{"location":"api/risk/#risk.BaseRisk._compute_mean","title":"_compute_mean","text":"<pre><code>_compute_mean(y_pred, y_true, **kwargs)\n</code></pre> <p>Compute the mean of the computed risks (ignoring NaNs).</p> <p>Parameters:</p> Name Type Description Default <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>y_true</code> <code>ndarray</code> <p>The true values.</p> required <code>**kwargs</code> <code>dict</code> <p>Additional keyword arguments (used in <code>compute</code>).</p> <code>{}</code> <p>Returns:</p> Type Description <code>float</code> <p>The mean of the computed risks.</p> Source code in <code>risk_control/risk.py</code> <pre><code>def _compute_mean(self, y_pred: np.ndarray, y_true: np.ndarray, **kwargs) -&gt; float:\n    \"\"\"\n    Compute the mean of the computed risks (ignoring NaNs).\n\n    Parameters\n    ----------\n    y_pred : np.ndarray\n        The predicted values.\n    y_true : np.ndarray\n        The true values.\n    **kwargs : dict\n        Additional keyword arguments (used in [`compute`][risk.BaseRisk.compute]).\n\n    Returns\n    -------\n    float\n        The mean of the computed risks.\n    \"\"\"\n    return np.nanmean(self.compute(y_pred, y_true, **kwargs))\n</code></pre>"},{"location":"api/risk/#risk.BaseRisk.compute","title":"compute  <code>abstractmethod</code>","text":"<pre><code>compute(y_pred, y_true, **kwargs)\n</code></pre> <p>Compute the risks based on predictions and true values.</p> <p>This method should be implemented in a subclass.</p> <p>Parameters:</p> Name Type Description Default <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>y_true</code> <code>ndarray</code> <p>The true values.</p> required <code>**kwargs</code> <code>dict</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The computed risks.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If this method is not implemented in a subclass.</p> Source code in <code>risk_control/risk.py</code> <pre><code>@abstractmethod\ndef compute(self, y_pred: np.ndarray, y_true: np.ndarray, **kwargs) -&gt; np.ndarray:\n    \"\"\"\n    Compute the risks based on predictions and true values.\n\n    This method should be implemented in a subclass.\n\n    Parameters\n    ----------\n    y_pred : np.ndarray\n        The predicted values.\n    y_true : np.ndarray\n        The true values.\n    **kwargs : dict\n        Additional keyword arguments.\n\n    Returns\n    -------\n    np.ndarray\n        The computed risks.\n\n    Raises\n    ------\n    NotImplementedError\n        If this method is not implemented in a subclass.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/risk/#risk.MSERisk","title":"MSERisk","text":"<pre><code>MSERisk(acceptable_risk, *, mse_max=1.0)\n</code></pre> <p>               Bases: <code>BaseRisk</code></p> <p>A class used to compute risks based on Mean Squared Error (MSE).</p> <p>Parameters:</p> Name Type Description Default <code>mse_max</code> <code>float</code> <p>The maximum value for Mean Squared Error (MSE).</p> <code>1.0</code> <p>Attributes:</p> Name Type Description <code>mse_max</code> <code>float</code> <p>The maximum value for Mean Squared Error (MSE).</p> <p>Methods:</p> Name Description <code>convert_to_performance</code> <p>Convert risk to performance measure.</p> <code>compute</code> <p>Computes the risks based on the predicted and true values.</p> Source code in <code>risk_control/risk.py</code> <pre><code>def __init__(self, acceptable_risk: float, *, mse_max: float = 1.0) -&gt; None:\n    super().__init__(acceptable_risk)\n    self.mse_max = mse_max\n    self.acceptable_risk = self.acceptable_risk / self.mse_max\n</code></pre>"},{"location":"api/risk/#risk.MSERisk.name","title":"name  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>name = 'mse'\n</code></pre>"},{"location":"api/risk/#risk.MSERisk.greater_is_better","title":"greater_is_better  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>greater_is_better = False\n</code></pre>"},{"location":"api/risk/#risk.MSERisk.mse_max","title":"mse_max  <code>instance-attribute</code>","text":"<pre><code>mse_max = mse_max\n</code></pre>"},{"location":"api/risk/#risk.MSERisk.acceptable_risk","title":"acceptable_risk  <code>instance-attribute</code>","text":"<pre><code>acceptable_risk = acceptable_risk / mse_max\n</code></pre>"},{"location":"api/risk/#risk.MSERisk.convert_to_performance","title":"convert_to_performance","text":"<pre><code>convert_to_performance(x)\n</code></pre> <p>Convert risk to performance measure. If the object is a risk, the performance measure is the risk.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>float</code> <p>The risk value.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The performance measure.</p> Source code in <code>risk_control/risk.py</code> <pre><code>def convert_to_performance(self, x: float) -&gt; float:\n    \"\"\"\n    Convert risk to performance measure.\n    If the object is a risk, the performance measure is the risk.\n\n    Parameters\n    ----------\n    x : float\n        The risk value.\n\n    Returns\n    -------\n    float\n        The performance measure.\n    \"\"\"\n    return x * self.mse_max\n</code></pre>"},{"location":"api/risk/#risk.MSERisk.compute","title":"compute","text":"<pre><code>compute(y_pred, y_true, **kwargs)\n</code></pre> <p>Computes the risks based on the predicted and true values.</p> <p>Parameters:</p> Name Type Description Default <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>y_true</code> <code>ndarray</code> <p>The true values.</p> required <code>**kwargs</code> <code>dict</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The computed risks.</p> Source code in <code>risk_control/risk.py</code> <pre><code>def compute(self, y_pred: np.ndarray, y_true: np.ndarray, **kwargs) -&gt; np.ndarray:\n    \"\"\"\n    Computes the risks based on the predicted and true values.\n\n    Parameters\n    ----------\n    y_pred : np.ndarray\n        The predicted values.\n    y_true : np.ndarray\n        The true values.\n    **kwargs : dict\n        Additional keyword arguments.\n\n    Returns\n    -------\n    np.ndarray\n        The computed risks.\n    \"\"\"\n    return np.clip((y_pred - y_true) ** 2 / self.mse_max, 0, 1)\n</code></pre>"},{"location":"api/risk/#risk.AccuracyRisk","title":"AccuracyRisk","text":"<pre><code>AccuracyRisk(acceptable_risk)\n</code></pre> <p>               Bases: <code>BaseRisk</code></p> <p>A class used to compute risks based on the accuracy of predictions.</p> <p>Only relevant for [<code>SelectiveClassification</code>][decision.SelectiveClassification].</p> <p>Methods:</p> Name Description <code>convert_to_performance</code> <p>Convert risk to performance measure.</p> <code>compute</code> <p>Compute risks based on the accuracy of predictions.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <code>greater_is_better</code> <code>bool</code> Source code in <code>risk_control/risk.py</code> <pre><code>def __init__(self, acceptable_risk: float):\n    self.acceptable_risk = acceptable_risk\n</code></pre>"},{"location":"api/risk/#risk.AccuracyRisk.name","title":"name  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>name = 'accuracy'\n</code></pre>"},{"location":"api/risk/#risk.AccuracyRisk.greater_is_better","title":"greater_is_better  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>greater_is_better = True\n</code></pre>"},{"location":"api/risk/#risk.AccuracyRisk.convert_to_performance","title":"convert_to_performance","text":"<pre><code>convert_to_performance(x)\n</code></pre> <p>Convert risk to performance measure. If the object is a risk, the performance measure is the risk.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>float</code> <p>The risk value.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The performance measure.</p> Source code in <code>risk_control/risk.py</code> <pre><code>def convert_to_performance(self, x: float) -&gt; float:\n    \"\"\"\n    Convert risk to performance measure.\n    If the object is a risk, the performance measure is the risk.\n\n    Parameters\n    ----------\n    x : float\n        The risk value.\n\n    Returns\n    -------\n    float\n        The performance measure.\n    \"\"\"\n    return 1 - x\n</code></pre>"},{"location":"api/risk/#risk.AccuracyRisk.compute","title":"compute","text":"<pre><code>compute(y_pred, y_true, **kwargs)\n</code></pre> <p>Compute risks based on the accuracy of predictions.</p> <p>Parameters:</p> Name Type Description Default <code>y_pred</code> <code>ndarray</code> <p>The predicted labels.</p> required <code>y_true</code> <code>ndarray</code> <p>The true labels.</p> required <code>**kwargs</code> <code>dict</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The computed risks.</p> Source code in <code>risk_control/risk.py</code> <pre><code>def compute(self, y_pred: np.ndarray, y_true: np.ndarray, **kwargs) -&gt; np.ndarray:\n    \"\"\"\n    Compute risks based on the accuracy of predictions.\n\n    Parameters\n    ----------\n    y_pred : np.ndarray\n        The predicted labels.\n    y_true : np.ndarray\n        The true labels.\n    **kwargs : dict\n        Additional keyword arguments.\n\n    Returns\n    -------\n    np.ndarray\n        The computed risks.\n    \"\"\"\n    indexes = np.any(y_pred, -1)\n    risks = 1.0 - (y_pred.argmax(-1) == y_true)\n    risks[indexes == False] = np.nan  # noqa: E712\n    return risks\n</code></pre>"},{"location":"api/risk/#risk.AccuracyRiskV2","title":"AccuracyRiskV2","text":"<pre><code>AccuracyRiskV2(acceptable_risk)\n</code></pre> <p>               Bases: <code>BaseRisk</code></p> <p>A class used to compute risks based on the accuracy of predictions.</p> <p>Methods:</p> Name Description <code>convert_to_performance</code> <p>Convert risk to performance measure.</p> <code>compute</code> <p>Compute risks based on the accuracy of predictions.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <code>greater_is_better</code> <code>bool</code> Source code in <code>risk_control/risk.py</code> <pre><code>def __init__(self, acceptable_risk: float):\n    self.acceptable_risk = acceptable_risk\n</code></pre>"},{"location":"api/risk/#risk.AccuracyRiskV2.name","title":"name  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>name = 'accuracy_v2'\n</code></pre>"},{"location":"api/risk/#risk.AccuracyRiskV2.greater_is_better","title":"greater_is_better  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>greater_is_better = True\n</code></pre>"},{"location":"api/risk/#risk.AccuracyRiskV2.convert_to_performance","title":"convert_to_performance","text":"<pre><code>convert_to_performance(x)\n</code></pre> <p>Convert risk to performance measure. If the object is a risk, the performance measure is the risk.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>float</code> <p>The risk value.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The performance measure.</p> Source code in <code>risk_control/risk.py</code> <pre><code>def convert_to_performance(self, x: float) -&gt; float:\n    \"\"\"\n    Convert risk to performance measure.\n    If the object is a risk, the performance measure is the risk.\n\n    Parameters\n    ----------\n    x : float\n        The risk value.\n\n    Returns\n    -------\n    float\n        The performance measure.\n    \"\"\"\n    return 1 - x\n</code></pre>"},{"location":"api/risk/#risk.AccuracyRiskV2.compute","title":"compute","text":"<pre><code>compute(y_pred, y_true, **kwargs)\n</code></pre> <p>Compute risks based on the accuracy of predictions.</p> <p>Parameters:</p> Name Type Description Default <code>y_pred</code> <code>ndarray</code> <p>The predicted labels.</p> required <code>y_true</code> <code>ndarray</code> <p>The true labels.</p> required <code>**kwargs</code> <code>dict</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The computed risks.</p> Source code in <code>risk_control/risk.py</code> <pre><code>def compute(self, y_pred: np.ndarray, y_true: np.ndarray, **kwargs) -&gt; np.ndarray:\n    \"\"\"\n    Compute risks based on the accuracy of predictions.\n\n    Parameters\n    ----------\n    y_pred : np.ndarray\n        The predicted labels.\n    y_true : np.ndarray\n        The true labels.\n    **kwargs : dict\n        Additional keyword arguments.\n\n    Returns\n    -------\n    np.ndarray\n        The computed risks.\n    \"\"\"\n    risks = 1.0 - (y_pred == y_true)\n    risks[np.isnan(y_pred)] = np.nan\n    return risks\n</code></pre>"},{"location":"api/risk/#risk.CoverageRisk","title":"CoverageRisk","text":"<pre><code>CoverageRisk(acceptable_risk)\n</code></pre> <p>               Bases: <code>BaseRisk</code></p> <p>A class used to compute risks based on the coverage of prediction sets.</p> <p>Relevant for [<code>MultiSelectiveClassification</code>][decision.MultiSelectiveClassification]. Compatible with [<code>SelectiveClassification</code>][decision.SelectiveClassification].</p> <p>Methods:</p> Name Description <code>convert_to_performance</code> <p>Convert risk to performance measure.</p> <code>compute</code> <p>Compute risks based on the coverage of prediction sets.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <code>greater_is_better</code> <code>bool</code> Source code in <code>risk_control/risk.py</code> <pre><code>def __init__(self, acceptable_risk: float):\n    self.acceptable_risk = acceptable_risk\n</code></pre>"},{"location":"api/risk/#risk.CoverageRisk.name","title":"name  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>name = 'coverage'\n</code></pre>"},{"location":"api/risk/#risk.CoverageRisk.greater_is_better","title":"greater_is_better  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>greater_is_better = True\n</code></pre>"},{"location":"api/risk/#risk.CoverageRisk.convert_to_performance","title":"convert_to_performance","text":"<pre><code>convert_to_performance(x)\n</code></pre> <p>Convert risk to performance measure. If the object is a risk, the performance measure is the risk.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>float</code> <p>The risk value.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The performance measure.</p> Source code in <code>risk_control/risk.py</code> <pre><code>def convert_to_performance(self, x: float) -&gt; float:\n    \"\"\"\n    Convert risk to performance measure.\n    If the object is a risk, the performance measure is the risk.\n\n    Parameters\n    ----------\n    x : float\n        The risk value.\n\n    Returns\n    -------\n    float\n        The performance measure.\n    \"\"\"\n    return 1 - x\n</code></pre>"},{"location":"api/risk/#risk.CoverageRisk.compute","title":"compute","text":"<pre><code>compute(y_pred, y_true, **kwargs)\n</code></pre> <p>Compute risks based on the coverage of prediction sets.</p> <p>Parameters:</p> Name Type Description Default <code>y_pred</code> <code>ndarray</code> <p>The predicted labels.</p> required <code>y_true</code> <code>ndarray</code> <p>The true labels.</p> required <code>**kwargs</code> <code>dict</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The computed risks.</p> Source code in <code>risk_control/risk.py</code> <pre><code>def compute(self, y_pred: np.ndarray, y_true: np.ndarray, **kwargs) -&gt; np.ndarray:\n    \"\"\"\n    Compute risks based on the coverage of prediction sets.\n\n    Parameters\n    ----------\n    y_pred : np.ndarray\n        The predicted labels.\n    y_true : np.ndarray\n        The true labels.\n    **kwargs : dict\n        Additional keyword arguments.\n\n    Returns\n    -------\n    np.ndarray\n        The computed risks.\n    \"\"\"\n    n_samples, _ = y_pred.shape\n    return 1 - (y_pred[np.arange(n_samples), y_true])\n</code></pre>"},{"location":"api/risk/#risk.RatioPredictionRisk","title":"RatioPredictionRisk","text":"<pre><code>RatioPredictionRisk(acceptable_risk)\n</code></pre> <p>               Bases: <code>BaseRisk</code></p> <p>A class used to compute risks based on the ratio human/machine predictions.</p> <p>Methods:</p> Name Description <code>convert_to_performance</code> <p>Convert risk to performance measure.</p> <code>compute</code> <p>Compute risks based on the ratio human/machine predictions.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <code>greater_is_better</code> <code>bool</code> Source code in <code>risk_control/risk.py</code> <pre><code>def __init__(self, acceptable_risk: float):\n    self.acceptable_risk = acceptable_risk\n</code></pre>"},{"location":"api/risk/#risk.RatioPredictionRisk.name","title":"name  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>name = 'pred_ratio'\n</code></pre>"},{"location":"api/risk/#risk.RatioPredictionRisk.greater_is_better","title":"greater_is_better  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>greater_is_better = True\n</code></pre>"},{"location":"api/risk/#risk.RatioPredictionRisk.convert_to_performance","title":"convert_to_performance","text":"<pre><code>convert_to_performance(x)\n</code></pre> <p>Convert risk to performance measure. If the object is a risk, the performance measure is the risk.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>float</code> <p>The risk value.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The performance measure.</p> Source code in <code>risk_control/risk.py</code> <pre><code>def convert_to_performance(self, x: float) -&gt; float:\n    \"\"\"\n    Convert risk to performance measure.\n    If the object is a risk, the performance measure is the risk.\n\n    Parameters\n    ----------\n    x : float\n        The risk value.\n\n    Returns\n    -------\n    float\n        The performance measure.\n    \"\"\"\n    return 1 - x\n</code></pre>"},{"location":"api/risk/#risk.RatioPredictionRisk.compute","title":"compute","text":"<pre><code>compute(y_pred, y_true, **kwargs)\n</code></pre> <p>Compute risks based on the ratio human/machine predictions.</p> <ul> <li>Machine predictions are assumed to be not NaN.</li> <li>Human predictions are assumed to be NaN.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>y_pred</code> <code>ndarray</code> <p>The predicted labels.</p> required <code>y_true</code> <code>ndarray</code> <p>The true labels.</p> required <code>**kwargs</code> <code>dict</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The computed risks.</p> Source code in <code>risk_control/risk.py</code> <pre><code>def compute(self, y_pred: np.ndarray, y_true: np.ndarray, **kwargs) -&gt; np.ndarray:\n    \"\"\"\n    Compute risks based on the ratio human/machine predictions.\n\n    - Machine predictions are assumed to be not NaN.\n    - Human predictions are assumed to be NaN.\n\n    Parameters\n    ----------\n    y_pred : np.ndarray\n        The predicted labels.\n    y_true : np.ndarray\n        The true labels.\n    **kwargs : dict\n        Additional keyword arguments.\n\n    Returns\n    -------\n    np.ndarray\n        The computed risks.\n    \"\"\"\n    if y_pred.ndim == 1:\n        return np.isnan(y_pred)\n    else:\n        return 1 - np.any(y_pred, -1)\n</code></pre>"},{"location":"api/risk_control/","title":"Controller Module","text":""},{"location":"api/risk_control/#risk_control","title":"Controller Module","text":""},{"location":"api/risk_control/#risk_control--risk-control-for-conformal-prediction","title":"Risk control for conformal prediction","text":"<p>This module contains the class <code>MapieRiskControl</code> which is used to control the risk of conformal prediction.</p> <p>Classes:</p> Name Description <code>MapieRiskControl</code> <p>Risk control for conformal prediction.</p>"},{"location":"api/risk_control/#risk_control.MapieRiskControl","title":"MapieRiskControl","text":"<p>Risk control for conformal prediction.</p>"},{"location":"api/risk_control/#risk_control.MapieRiskControl--which-control-method-to-use","title":"Which control method to use?","text":"<p>The control method consists in choosing a lambda value that controls the risk (defined by the user) at a given level (also defined by the user). Based on multiple testing, the control method gives a set of lambda values that control the risk. But the user has to choose one of them. And the strategy to choose depends on the type of risk and the type of decision. Here are the different strategies:</p> <ul> <li>\"lmin\" : smallest lambda for which the risk is acceptable</li> <li>\"lmax\" : largest lambda for which the risk is acceptable</li> <li>\"rmin\" : optimal lambda for which the risk is minimized and acceptable</li> <li>\"rmax\" : optimal lambda for which the risk is maximized and acceptable</li> </ul>"},{"location":"api/risk_control/#risk_control.MapieRiskControl--which-pvalues-methods-to-use","title":"Which pvalues methods to use?","text":"<p>The pvalues method consists in computing p-values for each lambda value. These p-values are used to control the risk. The possible methods to compute p-values are:</p> <ul> <li>\"clt\" : Central Limit Theorem, which is a normal approximation of the distribution of the risk.</li> <li>\"hb\" : Hoeffding-Bentkus Inequality, which is a concentration inequality for the distribution of the risk.</li> </ul>"},{"location":"api/risk_control/#risk_control.MapieRiskControl--which-fwer-method-to-use","title":"Which FWER method to use?","text":"<p>The FWER method (for Family-Wise Error Rate) is used to control the risk for multiple testing. Why? Because we have a set of lambda values, and we want to control the risk for all of them. They are possible methods:</p> <ul> <li>\"bonferroni\" : Bonferroni Correction, which is a simple but conservative method that divides the significance level by the number of comparisons.</li> <li>\"sgt\" : Sequential Graphical Testing (SGT), which is a more powerful method than Bonferroni Correction because it takes into account the space of hypothesis via a directed graph. The procedure sequentially tests the hypotheses at iteratively updayed significance levels.</li> </ul> <p>Attributes:</p> Name Type Description <code>decision</code> <code>BaseDecision</code> <p>The decision to be made.</p> <code>params</code> <code>BaseParameterSpace</code> <p>The parameter space of the decision. (The possible values of the lambda values).</p> <code>risks</code> <code>dict[str, BaseRisk]</code> <p>The risks to be controlled.</p> <code>delta</code> <code>float</code> <p>The desired error rate (see family-wise error rate method).</p> <code>pvalue_method</code> <code>str</code> <p>The method to estimate the p-values.</p> <code>fwer_method</code> <code>str</code> <p>The method to control the family-wise error rate.</p> <code>control_method</code> <code>str</code> <p>The method to choose the lambda value to control the risk.</p> <code>_n_samples</code> <code>int</code> <p>The number of samples.</p> <code>l_values</code> <code>list[dict]</code> <p>The list of lambda values (flattened parameter space).</p> <code>cr_results</code> <code>dict</code> <p>A dictionary containing the risk values for each lambda value. The dictionary has the following structure:</p> <ul> <li>f\"risks.{key}.values\": list of risk values for each lambda value.     (for each lambda value in rows and each sample in columns)</li> <li>f\"risks.{key}.mean\": list of mean risk values for each lambda value.</li> <li>f\"risks.{key}.std\": list of standard deviation of risk values for each lambda value.</li> <li>f\"risks.{key}.pvalue\": list of p-values for each lambda value.</li> <li>\"params\": list of all parameters for each lambda value.</li> <li>f\"params.{key}\" Additional keys for each parameter in the parameter space.</li> </ul> <code>valid_lambdas</code> <code>ndarray</code> <p>The valid lambda values (for which the p-value is less than alpha).</p> <code>valid_risks</code> <code>dict[str, ndarray]</code> <p>The valid risk values (for which the p-value is less than alpha) (keys are the risk names).</p> <code>l_star</code> <code>float</code> <p>The optimal lambda value (optimizing the risk).</p> <code>r_star</code> <code>float</code> <p>The optimal risk value.</p> <code>has_solution</code> <code>bool</code> <p>Whether a solution exists.</p> <code>_valid_pvalues_method</code> <code>dict</code> <p>The valid p-values methods.</p> <code>_valid_fwer_method</code> <code>dict</code> <p>The valid FWER methods.</p> <code>_valid_control_method</code> <code>dict</code> <p>The valid control methods (defining the criteria for selecting the optimal lambda value).</p> <p>Methods:</p> Name Description <code>__init__</code> <p>Initialize the MapieRiskControl class.</p> <code>evaluate</code> <p>Evaluate, for all lambda values (i.e., the grid of the decision function),</p> <code>test</code> <p>Test all hypotheses and identify valid lambda values that control the</p> <code>control</code> <p>Control the risk based on the specified method. The procedure is as follows:</p> <code>fit</code> <p>Fit the decision model on the input data, i.e.:</p> <code>predict</code> <p>Make predictions on the input data.</p> <code>summary</code> <p>Print a summary of the risk control results.</p> Source code in <code>risk_control/risk_control.py</code> <pre><code>class MapieRiskControl:\n    \"\"\"\n    Risk control for conformal prediction.\n\n    # Which control method to use?\n    The control method consists in choosing a lambda value that controls the risk\n    (defined by the user) at a given level (also defined by the user).\n    Based on multiple testing, the control method gives a set of lambda values\n    that control the risk. But the user has to choose one of them. And the\n    strategy to choose depends on the type of risk and the type of decision.\n    Here are the different strategies:\n\n    - \"lmin\" : smallest lambda for which the risk is acceptable\n    - \"lmax\" : largest lambda for which the risk is acceptable\n    - \"rmin\" : optimal lambda for which the risk is minimized\n    and acceptable\n    - \"rmax\" : optimal lambda for which the risk is maximized\n    and acceptable\n\n    # Which pvalues methods to use?\n    The pvalues method consists in computing p-values for each lambda value.\n    These p-values are used to control the risk. The possible methods to\n    compute p-values are:\n\n    - \"clt\" : Central Limit Theorem, which is a normal approximation of the\n    distribution of the risk.\n    - \"hb\" : Hoeffding-Bentkus Inequality, which is a concentration inequality\n    for the distribution of the risk.\n\n    # Which FWER method to use?\n    The FWER method (for Family-Wise Error Rate) is used to control the risk\n    for multiple testing. Why? Because we have a set of lambda values, and we\n    want to control the risk for all of them. They are possible methods:\n\n    - \"bonferroni\" : Bonferroni Correction, which is a simple but conservative\n    method that divides the significance level by the number of comparisons.\n    - \"sgt\" : Sequential Graphical Testing (SGT), which is a more powerful method\n    than Bonferroni Correction because it takes into account the space of\n    hypothesis via a directed graph. The procedure sequentially tests the hypotheses\n    at iteratively updayed significance levels.\n\n    Attributes\n    ----------\n    decision : BaseDecision\n        The decision to be made.\n    params: BaseParameterSpace\n        The parameter space of the decision.\n        (The possible values of the lambda values).\n    risks : dict[str, BaseRisk]\n        The risks to be controlled.\n    delta : float\n        The desired error rate (see family-wise error rate method).\n    pvalue_method : str\n        The method to estimate the p-values.\n    fwer_method : str\n        The method to control the family-wise error rate.\n    control_method : str\n        The method to choose the lambda value to control the risk.\n    _n_samples : int\n        The number of samples.\n    l_values : list[dict]\n        The list of lambda values (flattened parameter space).\n    cr_results : dict\n        A dictionary containing the risk values for each lambda value.\n        The dictionary has the following structure:\n\n        - f\"risks.{key}.values\": list of risk values for each lambda value.\n            (for each lambda value in rows and each sample in columns)\n        - f\"risks.{key}.mean\": list of mean risk values for each lambda value.\n        - f\"risks.{key}.std\": list of standard deviation of risk values for each lambda value.\n        - f\"risks.{key}.pvalue\": list of p-values for each lambda value.\n        - \"params\": list of all parameters for each lambda value.\n        - f\"params.{key}\" Additional keys for each parameter in the parameter space.\n    valid_lambdas : np.ndarray\n        The valid lambda values (for which the p-value is less than alpha).\n    valid_risks : dict[str, np.ndarray]\n        The valid risk values (for which the p-value is less than alpha)\n        (keys are the risk names).\n    l_star : float\n        The optimal lambda value (optimizing the risk).\n    r_star : float\n        The optimal risk value.\n    has_solution : bool\n        Whether a solution exists.\n    _valid_pvalues_method : dict\n        The valid p-values methods.\n    _valid_fwer_method : dict\n        The valid FWER methods.\n    _valid_control_method : dict\n        The valid control methods (defining the criteria for selecting the optimal\n        lambda value).\n    \"\"\"\n\n    _valid_pvalues_method = {\n        \"clt\": compute_clt_p_values,\n        \"hb\": compute_hb_p_values,\n    }\n\n    _valid_fwer_method = {\n        \"standard\": fwer_bonferroni,\n        # TODO: fixed sequence testing\n        \"sgt_old\": fwer_sgt,\n        \"sgt\": fwer_sgt_nd,\n    }\n\n    _valid_control_method = {\n        \"lmin\": lambda self: np.argmin(\n            [elt[self.ref_param] for elt in self.valid_lambdas]\n        ),  # TODO: not working because elements are dictionary\n        \"lmax\": lambda self: np.argmax(\n            [elt[self.ref_param] for elt in self.valid_lambdas]\n        ),  # TODO: not working because elements are dictionary\n        \"rmin\": lambda self: np.argmin(self.valid_risks[self.ref_risk]),\n        \"rmax\": lambda self: np.argmax(self.valid_risks[self.ref_risk]),\n    }\n\n    def __init__(\n        self,\n        decision: BaseDecision,\n        params: BaseParameterSpace,\n        risks: Union[BaseRisk, list[BaseRisk], dict[str, BaseRisk]],\n        *,\n        delta: float,\n        pvalue_method: str = \"clt\",\n        fwer_method: str = \"sgt\",\n        control_method: str = \"rmin\",\n    ) -&gt; None:\n        \"\"\"\n        Initialize the MapieRiskControl class.\n\n        Parameters\n        ----------\n        decision : BaseDecision\n            The decision object used for making predictions and decisions.\n        params : BaseParameterSpace\n            The parameter space for the risk control.\n        risks : Union[BaseRisk, list[BaseRisk], dict[str, BaseRisk]]\n            The risk object used for computing risk values.\n        delta : float\n            The desired error rate.\n        pvalue_method : str\n            The method to use for p-value computation (\"clt\" or \"hb\"), by default \"hb\".\n        fwer_method : str\n            The method to use for FWER control (\"standard\" or \"sgt\"), by default \"sgt\".\n        control_method : str\n            The method to use for risk control (\"lmin\", \"lmax\", \"rmin\", \"rmax\").\n\n        Raises\n        ------\n        AssertionError\n            If `pvalue_method`, `fwer_method` or `control_method` is not valid.\n        AssertionError\n            If `delta` is not in the interval (0, 1).\n        \"\"\"\n        self.decision = decision\n        self.params = params\n\n        self.risks: dict[str, BaseRisk]\n        if isinstance(risks, list):\n            self.risks = {risk_.name: risk_ for risk_ in risks}\n        elif isinstance(risks, BaseRisk):\n            self.risks = {risks.name: risks}\n        elif isinstance(risks, dict):\n            self.risks = risks\n\n        self.target_risks: dict[str, float] = {}\n        self.target_risks = {\n            risk_.name: risk_.acceptable_risk for risk_ in self.risks.values()\n        }\n\n        assert 0 &lt; delta &lt; 1, \"delta must be in (0, 1)\"\n        self.delta = delta\n\n        assert pvalue_method in self._valid_pvalues_method, \"Invalid pvalue_method\"\n        self.pvalue_method = pvalue_method\n\n        assert fwer_method in self._valid_fwer_method, \"Invalid fwer_method\"\n        self.fwer_method = fwer_method\n\n        assert control_method in self._valid_control_method, \"Invalid control_method\"\n        self.control_method = control_method\n\n        self.cr_results = self._initialize_cr_results()\n\n        self.ref_risk = list(self.risks.keys())[0]\n        self.ref_param = list(self.params.keys())[0]\n\n    def _initialize_cr_results(self) -&gt; dict[str, list[Any]]:\n        \"\"\"\n        Initialize the control results dictionary.\n\n        Returns\n        -------\n        dict[str, list[Any]]\n            The initialized control results dictionary.\n        \"\"\"\n        cr_results: dict[str, list[Any]] = {}\n\n        for key in self.risks.keys():\n            cr_results[f\"risks.{key}.values\"] = []\n            cr_results[f\"risks.{key}.mean\"] = []\n            cr_results[f\"risks.{key}.std\"] = []\n            cr_results[f\"risks.{key}.p_value\"] = []\n        cr_results[\"risks.AGG.p_value\"] = []\n\n        for key in self.params.keys():\n            cr_results[f\"params.{key}\"] = []\n        cr_results[\"params\"] = []\n\n        return cr_results\n\n    def _clone_decision_with_params(self, **params) -&gt; BaseDecision:\n        \"\"\"\n        Clone the decision object with the given parameters.\n\n        Parameters\n        ----------\n        **params : dict\n            The parameters to set on the cloned decision object.\n\n        Returns\n        -------\n        BaseDecision\n            The cloned decision object with the given parameters.\n        \"\"\"\n        decision_clone: BaseDecision = deepcopy(self.decision)\n        # TODO: clone(self.decision) # with scikit-learn\n        decision_clone.set_params(**params)\n        return decision_clone\n\n    def _get_all_combinations(self, params: dict) -&gt; list[dict]:\n        \"\"\"\n        Get all combinations of parameters.\n\n        Parameters\n        ----------\n        params : dict\n            The parameters and their possible values.\n\n        Returns\n        -------\n        list[dict]\n            All combinations of parameters.\n        tuple[int]\n            The shape of the combinations.\n        \"\"\"\n        keys = params.keys()\n        values = params.values()\n        combinations = [dict(zip(keys, v)) for v in product(*values)]\n        shape = tuple(len(v) for v in values)\n        assert len(combinations) == np.prod(shape)\n        return combinations, shape\n\n    def _estimate_risk(\n        self, X: np.ndarray, y: np.ndarray, l_values: list[dict[str, Any]], **kwargs\n    ) -&gt; dict:\n        \"\"\"\n        Estimate the risk for each lambda value.\n\n        Parameters\n        ----------\n        X : np.ndarray\n            The input features.\n        y : np.ndarray\n            The true labels.\n        l_values : list[dict[str, Any]]\n            The list of lambda values to evaluate.\n        **kwargs : dict\n            Additional keyword arguments for risk computation.\n\n        Returns\n        -------\n        cr_results : dict\n            A dictionary containing the risk values for each lambda value.\n            The dictionary has the following structure:\n\n            - f\"risks.{key}.values\": list of risk values for each lambda value.\n                (for each lambda value in rows and each sample in columns)\n            - f\"risks.{key}.mean\": list of mean risk values for each lambda value.\n            - f\"risks.{key}.std\": list of standard deviation of risk values for each lambda value.\n            - f\"risks.{key}.pvalue\": list of p-values for each lambda value.\n            - \"params\": list of all parameters for each lambda value.\n            - f\"params.{key}\" Additional keys for each parameter in the parameter space.\n        \"\"\"\n        cr_results: dict[str, list[Any]] = self._initialize_cr_results()\n\n        y_output = self.decision.make_prediction(X)\n        for l_value in l_values:\n            new_decision = self._clone_decision_with_params(**l_value)\n            y_decision = new_decision.make_decision(y_output)\n\n            for name_, risk_ in self.risks.items():\n                risks = risk_.compute(y_decision, y, **kwargs)\n                cr_results[f\"risks.{name_}.values\"].append(risks.tolist())\n                cr_results[f\"risks.{name_}.mean\"].append(np.nanmean(risks).tolist())\n                cr_results[f\"risks.{name_}.std\"].append(np.nanstd(risks).tolist())\n\n            cr_results[\"params\"].append(l_value)\n            for key, val in l_value.items():\n                cr_results[f\"params.{key}\"].append(val)\n\n        # convert lists to numpy arrays for easier manipulation\n        for key, val in cr_results.items():\n            cr_results[key] = np.array(val)\n\n        return cr_results\n\n    def evaluate(self, X: np.ndarray, y: np.ndarray, **kwargs) -&gt; None:\n        \"\"\"\n        Evaluate, for all lambda values (i.e., the grid of the decision function),\n        the risk values and means for the given data with respect to the decision\n        function and risk function.\n\n        It sets the `cr_results` attribute with the results of the evaluation.\n        Its a dictionary with the following structure:\n\n        - \"values\": list of risk values for each lambda value.\n        - \"mean\": list of mean risk values for each lambda value.\n        - \"std\": list of standard deviation of risk values for each lambda value.\n        - Additional keys for each parameter in the parameter space.\n\n        Parameters\n        ----------\n        X : np.ndarray\n            The input features.\n        y : np.ndarray\n            The true labels.\n        **kwargs : dict\n            Additional keyword arguments for risk estimation.\n\n        Raises\n        ------\n        AssertionError\n            If the number of samples in `X` and `y` do not match.\n        \"\"\"\n        assert X.shape[0] == y.shape[0]\n        self._n_samples = X.shape[0]\n\n        self.l_values, self.param_shape = self._get_all_combinations(self.params)\n        self.cr_results = self._estimate_risk(X, y, self.l_values, **kwargs)\n\n    def _estimate_pvalues(\n        self, values: np.ndarray, alpha: float, method: str\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Estimate p-values for the risk values.\n\n        Parameters\n        ----------\n        values : np.ndarray\n            The risk values with shape (n_params, n_samples).\n        alpha : float\n            The desired risk value.\n        method : str\n            The method to use for p-value computation (\"clt\" or \"hb\").\n\n        Returns\n        -------\n        np.ndarray\n            The computed p-values.\n\n        Raises\n        ------\n        AssertionError\n            If the method is not in the valid p-values methods.\n        \"\"\"\n        assert method in self._valid_pvalues_method\n        p_values = MapieRiskControl._valid_pvalues_method[method](\n            values, alpha, self._n_samples\n        )\n        return np.array(p_values)\n\n    def _control_fwer(\n        self, p_values: np.ndarray, delta: float, method: str\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Control the family-wise error rate (FWER).\n\n        Parameters\n        ----------\n        p_values : np.ndarray\n            The p-values with shape (n_params,).\n        delta : float\n            The desired error rate.\n        method : str\n            The method to use for FWER control (\"standard\" or \"sgt\").\n\n        Returns\n        -------\n        np.ndarray\n            The sorted indices of valid hypotheses.\n\n        Warns\n        -----\n        UserWarning\n            If no valid hypotheses are found.\n        \"\"\"\n        indexes = MapieRiskControl._valid_fwer_method[method](\n            p_values, delta, self.param_shape\n        )\n\n        if not len(indexes):\n            warnings.warn(\"No valid hypotheses.\")\n            return np.array([])\n        else:\n            return np.sort(indexes)\n\n    def test(self) -&gt; None:\n        \"\"\"\n        Test all hypotheses and identify valid lambda values that control the\n        risk and family-wise error rate. The procedure is as follows:\n\n        1. Estimate p-values for each lambda (with\n        [`_estimate_pvalues`][risk_control.MapieRiskControl._estimate_pvalues]\n        method).\n        2. Control the family-wise error rate (with\n        [`_control_fwer`][risk_control.MapieRiskControl._control_fwer] method).\n        3. Store the valid lambda values (`valid_lambdas`)\n        and their corresponding risks (`valid_risks`).\n        \"\"\"\n        for name_ in self.risks.keys():\n            self.cr_results[f\"risks.{name_}.p_value\"] = self._estimate_pvalues(\n                values=self.cr_results[f\"risks.{name_}.values\"],\n                alpha=self.target_risks[name_],\n                method=self.pvalue_method,\n            )\n\n        self.cr_specific_results = {}\n        for name_ in self.risks.keys():\n            indexes = self._control_fwer(\n                p_values=self.cr_results[f\"risks.{name_}.p_value\"],\n                delta=self.delta,\n                method=self.fwer_method,\n            )\n            if len(indexes) &gt; 0:\n                self.cr_specific_results[name_] = {\n                    \"valid_lambdas\": self.cr_results[\"params\"][indexes],\n                    \"valid_risks\": self.cr_results[f\"risks.{name_}.mean\"][indexes],\n                    \"p_values\": self.cr_results[f\"risks.{name_}.p_value\"],\n                }\n            else:\n                self.cr_specific_results[name_] = {\n                    \"valid_lambdas\": [],\n                    \"valid_risks\": [],\n                    \"p_values\": self.cr_results[f\"risks.{name_}.p_value\"],\n                }\n\n        p_values = np.array(\n            [self.cr_results[f\"risks.{name_}.p_value\"] for name_ in self.risks.keys()]\n        )\n        p_values = p_values.max(axis=0)\n        self.cr_results[\"risks.AGG.p_value\"] = p_values\n\n        indexes = self._control_fwer(\n            p_values=p_values,\n            delta=self.delta,\n            method=self.fwer_method,\n        )\n\n        self.has_solution = len(indexes) &gt; 0\n\n        if self.has_solution:\n            self.valid_lambdas = self.cr_results[\"params\"][indexes]\n            self.valid_risks = {\n                name_: self.cr_results[f\"risks.{name_}.mean\"][indexes]\n                for name_ in self.risks.keys()\n            }\n        else:\n            self.valid_lambdas = []\n            self.valid_risks = {}\n\n    def control(self) -&gt; None:\n        \"\"\"\n        Control the risk based on the specified method. The procedure is as follows:\n\n        1. Check if a solution exists (`has_solution`).\n        2. If a solution exists, select the optimal lambda value (`l_star`) and\n          corresponding risk (`r_star`) based on the control method.\n        3. Set the parameters of the decision model to the optimal lambda value.\n\n        Raises\n        ------\n        ValueError\n            If no solution is found for risk control.\n        \"\"\"\n        if (\n            not self.has_solution\n        ):  # raise ValueError(\"No solution found for risk control.\")\n            self.l_star = None\n            self.r_star = None\n            return\n\n        idx = MapieRiskControl._valid_control_method[self.control_method](self)\n\n        self.l_star: dict[str, float] = self.valid_lambdas[idx]  # type: ignore\n        self.r_star: dict[str, float] = {\n            name_: valid_risks_[idx] for name_, valid_risks_ in self.valid_risks.items()\n        }  # type: ignore\n        if self.l_star:\n            self.decision.set_params(**self.l_star)\n\n    def fit(self, X: np.ndarray, y: np.ndarray, **kwargs):\n        \"\"\"\n        Fit the decision model on the input data, i.e.:\n\n        1. Evaluate the decision model on the calibration data.\n        2. Compute the p-values for the risk control.\n        3. Find the valid lambdas for the risk control.\n        4. Find the optimal lambda for the risk control.\n\n        Parameters\n        ----------\n        X : np.ndarray\n            The input features.\n        y : np.ndarray\n            The target labels.\n        **kwargs : dict\n            Additional keyword arguments to pass to the `evaluate` method.\n\n        Returns\n        -------\n        self : MapieRiskControl\n            The fitted risk control model.\n        \"\"\"\n        self.evaluate(X, y, **kwargs)\n        self.test()\n        self.control()\n        return self\n\n    def predict(self, X: np.ndarray) -&gt; np.ndarray:\n        \"\"\"\n        Make predictions on the input data.\n\n        Parameters\n        ----------\n        X : np.ndarray\n            The input features.\n\n        Returns\n        -------\n        np.ndarray\n            The predicted labels.\n        \"\"\"\n        return self.decision.predict(X)\n\n    def summary(self) -&gt; None:\n        \"\"\"\n        Print a summary of the risk control results.\n        \"\"\"\n        print(\"=== SUMMARY ===\")\n        print(\"p(risk&lt;=alpha) &gt;= 1-delta\")\n        print(f\"1-delta: {1 - self.delta:.2f}\")\n        print(\"=== risks ===\")\n        for name_, risk_ in self.risks.items():\n            r_star = (\n                risk_.convert_to_performance(self.r_star[name_])\n                if self.r_star\n                else np.inf\n            )\n            alpha = risk_.convert_to_performance(self.target_risks[name_])\n            print(f\"{name_}\\t| optimal: {r_star:.2f}\\t| alpha: {alpha:.2}\")\n        print(\"=== params ===\")\n        for name_ in self.params.keys():\n            l_star = self.l_star[name_] if self.l_star else np.inf\n            print(f\"{name_}\\t| optimal: {l_star:.2f}\")\n</code></pre>"},{"location":"api/risk_control/#risk_control.MapieRiskControl._valid_pvalues_method","title":"_valid_pvalues_method  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>_valid_pvalues_method = {\n    \"clt\": compute_clt_p_values,\n    \"hb\": compute_hb_p_values,\n}\n</code></pre>"},{"location":"api/risk_control/#risk_control.MapieRiskControl._valid_fwer_method","title":"_valid_fwer_method  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>_valid_fwer_method = {\n    \"standard\": fwer_bonferroni,\n    \"sgt_old\": fwer_sgt,\n    \"sgt\": fwer_sgt_nd,\n}\n</code></pre>"},{"location":"api/risk_control/#risk_control.MapieRiskControl._valid_control_method","title":"_valid_control_method  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>_valid_control_method = {\n    \"lmin\": lambda self: argmin(\n        [elt[ref_param] for elt in valid_lambdas]\n    ),\n    \"lmax\": lambda self: argmax(\n        [elt[ref_param] for elt in valid_lambdas]\n    ),\n    \"rmin\": lambda self: argmin(valid_risks[ref_risk]),\n    \"rmax\": lambda self: argmax(valid_risks[ref_risk]),\n}\n</code></pre>"},{"location":"api/risk_control/#risk_control.MapieRiskControl.decision","title":"decision  <code>instance-attribute</code>","text":"<pre><code>decision = decision\n</code></pre>"},{"location":"api/risk_control/#risk_control.MapieRiskControl.params","title":"params  <code>instance-attribute</code>","text":"<pre><code>params = params\n</code></pre>"},{"location":"api/risk_control/#risk_control.MapieRiskControl.risks","title":"risks  <code>instance-attribute</code>","text":"<pre><code>risks\n</code></pre>"},{"location":"api/risk_control/#risk_control.MapieRiskControl.target_risks","title":"target_risks  <code>instance-attribute</code>","text":"<pre><code>target_risks = {name: _gn5CLHQFj0MQCZfor risk_ in values()}\n</code></pre>"},{"location":"api/risk_control/#risk_control.MapieRiskControl.delta","title":"delta  <code>instance-attribute</code>","text":"<pre><code>delta = delta\n</code></pre>"},{"location":"api/risk_control/#risk_control.MapieRiskControl.pvalue_method","title":"pvalue_method  <code>instance-attribute</code>","text":"<pre><code>pvalue_method = pvalue_method\n</code></pre>"},{"location":"api/risk_control/#risk_control.MapieRiskControl.fwer_method","title":"fwer_method  <code>instance-attribute</code>","text":"<pre><code>fwer_method = fwer_method\n</code></pre>"},{"location":"api/risk_control/#risk_control.MapieRiskControl.control_method","title":"control_method  <code>instance-attribute</code>","text":"<pre><code>control_method = control_method\n</code></pre>"},{"location":"api/risk_control/#risk_control.MapieRiskControl.cr_results","title":"cr_results  <code>instance-attribute</code>","text":"<pre><code>cr_results = _initialize_cr_results()\n</code></pre>"},{"location":"api/risk_control/#risk_control.MapieRiskControl.ref_risk","title":"ref_risk  <code>instance-attribute</code>","text":"<pre><code>ref_risk = list(keys())[0]\n</code></pre>"},{"location":"api/risk_control/#risk_control.MapieRiskControl.ref_param","title":"ref_param  <code>instance-attribute</code>","text":"<pre><code>ref_param = list(keys())[0]\n</code></pre>"},{"location":"api/risk_control/#risk_control.MapieRiskControl.__init__","title":"__init__","text":"<pre><code>__init__(\n    decision,\n    params,\n    risks,\n    *,\n    delta,\n    pvalue_method=\"clt\",\n    fwer_method=\"sgt\",\n    control_method=\"rmin\"\n)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>decision</code> <code>BaseDecision</code> <p>The decision object used for making predictions and decisions.</p> required <code>params</code> <code>BaseParameterSpace</code> <p>The parameter space for the risk control.</p> required <code>risks</code> <code>Union[BaseRisk, list[BaseRisk], dict[str, BaseRisk]]</code> <p>The risk object used for computing risk values.</p> required <code>delta</code> <code>float</code> <p>The desired error rate.</p> required <code>pvalue_method</code> <code>str</code> <p>The method to use for p-value computation (\"clt\" or \"hb\"), by default \"hb\".</p> <code>'clt'</code> <code>fwer_method</code> <code>str</code> <p>The method to use for FWER control (\"standard\" or \"sgt\"), by default \"sgt\".</p> <code>'sgt'</code> <code>control_method</code> <code>str</code> <p>The method to use for risk control (\"lmin\", \"lmax\", \"rmin\", \"rmax\").</p> <code>'rmin'</code> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If <code>pvalue_method</code>, <code>fwer_method</code> or <code>control_method</code> is not valid.</p> <code>AssertionError</code> <p>If <code>delta</code> is not in the interval (0, 1).</p> Source code in <code>risk_control/risk_control.py</code> <pre><code>def __init__(\n    self,\n    decision: BaseDecision,\n    params: BaseParameterSpace,\n    risks: Union[BaseRisk, list[BaseRisk], dict[str, BaseRisk]],\n    *,\n    delta: float,\n    pvalue_method: str = \"clt\",\n    fwer_method: str = \"sgt\",\n    control_method: str = \"rmin\",\n) -&gt; None:\n    \"\"\"\n    Initialize the MapieRiskControl class.\n\n    Parameters\n    ----------\n    decision : BaseDecision\n        The decision object used for making predictions and decisions.\n    params : BaseParameterSpace\n        The parameter space for the risk control.\n    risks : Union[BaseRisk, list[BaseRisk], dict[str, BaseRisk]]\n        The risk object used for computing risk values.\n    delta : float\n        The desired error rate.\n    pvalue_method : str\n        The method to use for p-value computation (\"clt\" or \"hb\"), by default \"hb\".\n    fwer_method : str\n        The method to use for FWER control (\"standard\" or \"sgt\"), by default \"sgt\".\n    control_method : str\n        The method to use for risk control (\"lmin\", \"lmax\", \"rmin\", \"rmax\").\n\n    Raises\n    ------\n    AssertionError\n        If `pvalue_method`, `fwer_method` or `control_method` is not valid.\n    AssertionError\n        If `delta` is not in the interval (0, 1).\n    \"\"\"\n    self.decision = decision\n    self.params = params\n\n    self.risks: dict[str, BaseRisk]\n    if isinstance(risks, list):\n        self.risks = {risk_.name: risk_ for risk_ in risks}\n    elif isinstance(risks, BaseRisk):\n        self.risks = {risks.name: risks}\n    elif isinstance(risks, dict):\n        self.risks = risks\n\n    self.target_risks: dict[str, float] = {}\n    self.target_risks = {\n        risk_.name: risk_.acceptable_risk for risk_ in self.risks.values()\n    }\n\n    assert 0 &lt; delta &lt; 1, \"delta must be in (0, 1)\"\n    self.delta = delta\n\n    assert pvalue_method in self._valid_pvalues_method, \"Invalid pvalue_method\"\n    self.pvalue_method = pvalue_method\n\n    assert fwer_method in self._valid_fwer_method, \"Invalid fwer_method\"\n    self.fwer_method = fwer_method\n\n    assert control_method in self._valid_control_method, \"Invalid control_method\"\n    self.control_method = control_method\n\n    self.cr_results = self._initialize_cr_results()\n\n    self.ref_risk = list(self.risks.keys())[0]\n    self.ref_param = list(self.params.keys())[0]\n</code></pre>"},{"location":"api/risk_control/#risk_control.MapieRiskControl._initialize_cr_results","title":"_initialize_cr_results","text":"<pre><code>_initialize_cr_results()\n</code></pre> <p>Initialize the control results dictionary.</p> <p>Returns:</p> Type Description <code>dict[str, list[Any]]</code> <p>The initialized control results dictionary.</p> Source code in <code>risk_control/risk_control.py</code> <pre><code>def _initialize_cr_results(self) -&gt; dict[str, list[Any]]:\n    \"\"\"\n    Initialize the control results dictionary.\n\n    Returns\n    -------\n    dict[str, list[Any]]\n        The initialized control results dictionary.\n    \"\"\"\n    cr_results: dict[str, list[Any]] = {}\n\n    for key in self.risks.keys():\n        cr_results[f\"risks.{key}.values\"] = []\n        cr_results[f\"risks.{key}.mean\"] = []\n        cr_results[f\"risks.{key}.std\"] = []\n        cr_results[f\"risks.{key}.p_value\"] = []\n    cr_results[\"risks.AGG.p_value\"] = []\n\n    for key in self.params.keys():\n        cr_results[f\"params.{key}\"] = []\n    cr_results[\"params\"] = []\n\n    return cr_results\n</code></pre>"},{"location":"api/risk_control/#risk_control.MapieRiskControl._clone_decision_with_params","title":"_clone_decision_with_params","text":"<pre><code>_clone_decision_with_params(**params)\n</code></pre> <p>Clone the decision object with the given parameters.</p> <p>Parameters:</p> Name Type Description Default <code>**params</code> <code>dict</code> <p>The parameters to set on the cloned decision object.</p> <code>{}</code> <p>Returns:</p> Type Description <code>BaseDecision</code> <p>The cloned decision object with the given parameters.</p> Source code in <code>risk_control/risk_control.py</code> <pre><code>def _clone_decision_with_params(self, **params) -&gt; BaseDecision:\n    \"\"\"\n    Clone the decision object with the given parameters.\n\n    Parameters\n    ----------\n    **params : dict\n        The parameters to set on the cloned decision object.\n\n    Returns\n    -------\n    BaseDecision\n        The cloned decision object with the given parameters.\n    \"\"\"\n    decision_clone: BaseDecision = deepcopy(self.decision)\n    # TODO: clone(self.decision) # with scikit-learn\n    decision_clone.set_params(**params)\n    return decision_clone\n</code></pre>"},{"location":"api/risk_control/#risk_control.MapieRiskControl._get_all_combinations","title":"_get_all_combinations","text":"<pre><code>_get_all_combinations(params)\n</code></pre> <p>Get all combinations of parameters.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>dict</code> <p>The parameters and their possible values.</p> required <p>Returns:</p> Type Description <code>list[dict]</code> <p>All combinations of parameters.</p> <code>tuple[int]</code> <p>The shape of the combinations.</p> Source code in <code>risk_control/risk_control.py</code> <pre><code>def _get_all_combinations(self, params: dict) -&gt; list[dict]:\n    \"\"\"\n    Get all combinations of parameters.\n\n    Parameters\n    ----------\n    params : dict\n        The parameters and their possible values.\n\n    Returns\n    -------\n    list[dict]\n        All combinations of parameters.\n    tuple[int]\n        The shape of the combinations.\n    \"\"\"\n    keys = params.keys()\n    values = params.values()\n    combinations = [dict(zip(keys, v)) for v in product(*values)]\n    shape = tuple(len(v) for v in values)\n    assert len(combinations) == np.prod(shape)\n    return combinations, shape\n</code></pre>"},{"location":"api/risk_control/#risk_control.MapieRiskControl._estimate_risk","title":"_estimate_risk","text":"<pre><code>_estimate_risk(X, y, l_values, **kwargs)\n</code></pre> <p>Estimate the risk for each lambda value.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>The input features.</p> required <code>y</code> <code>ndarray</code> <p>The true labels.</p> required <code>l_values</code> <code>list[dict[str, Any]]</code> <p>The list of lambda values to evaluate.</p> required <code>**kwargs</code> <code>dict</code> <p>Additional keyword arguments for risk computation.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>cr_results</code> <code>dict</code> <p>A dictionary containing the risk values for each lambda value. The dictionary has the following structure:</p> <ul> <li>f\"risks.{key}.values\": list of risk values for each lambda value.     (for each lambda value in rows and each sample in columns)</li> <li>f\"risks.{key}.mean\": list of mean risk values for each lambda value.</li> <li>f\"risks.{key}.std\": list of standard deviation of risk values for each lambda value.</li> <li>f\"risks.{key}.pvalue\": list of p-values for each lambda value.</li> <li>\"params\": list of all parameters for each lambda value.</li> <li>f\"params.{key}\" Additional keys for each parameter in the parameter space.</li> </ul> Source code in <code>risk_control/risk_control.py</code> <pre><code>def _estimate_risk(\n    self, X: np.ndarray, y: np.ndarray, l_values: list[dict[str, Any]], **kwargs\n) -&gt; dict:\n    \"\"\"\n    Estimate the risk for each lambda value.\n\n    Parameters\n    ----------\n    X : np.ndarray\n        The input features.\n    y : np.ndarray\n        The true labels.\n    l_values : list[dict[str, Any]]\n        The list of lambda values to evaluate.\n    **kwargs : dict\n        Additional keyword arguments for risk computation.\n\n    Returns\n    -------\n    cr_results : dict\n        A dictionary containing the risk values for each lambda value.\n        The dictionary has the following structure:\n\n        - f\"risks.{key}.values\": list of risk values for each lambda value.\n            (for each lambda value in rows and each sample in columns)\n        - f\"risks.{key}.mean\": list of mean risk values for each lambda value.\n        - f\"risks.{key}.std\": list of standard deviation of risk values for each lambda value.\n        - f\"risks.{key}.pvalue\": list of p-values for each lambda value.\n        - \"params\": list of all parameters for each lambda value.\n        - f\"params.{key}\" Additional keys for each parameter in the parameter space.\n    \"\"\"\n    cr_results: dict[str, list[Any]] = self._initialize_cr_results()\n\n    y_output = self.decision.make_prediction(X)\n    for l_value in l_values:\n        new_decision = self._clone_decision_with_params(**l_value)\n        y_decision = new_decision.make_decision(y_output)\n\n        for name_, risk_ in self.risks.items():\n            risks = risk_.compute(y_decision, y, **kwargs)\n            cr_results[f\"risks.{name_}.values\"].append(risks.tolist())\n            cr_results[f\"risks.{name_}.mean\"].append(np.nanmean(risks).tolist())\n            cr_results[f\"risks.{name_}.std\"].append(np.nanstd(risks).tolist())\n\n        cr_results[\"params\"].append(l_value)\n        for key, val in l_value.items():\n            cr_results[f\"params.{key}\"].append(val)\n\n    # convert lists to numpy arrays for easier manipulation\n    for key, val in cr_results.items():\n        cr_results[key] = np.array(val)\n\n    return cr_results\n</code></pre>"},{"location":"api/risk_control/#risk_control.MapieRiskControl.evaluate","title":"evaluate","text":"<pre><code>evaluate(X, y, **kwargs)\n</code></pre> <p>Evaluate, for all lambda values (i.e., the grid of the decision function), the risk values and means for the given data with respect to the decision function and risk function.</p> <p>It sets the <code>cr_results</code> attribute with the results of the evaluation. Its a dictionary with the following structure:</p> <ul> <li>\"values\": list of risk values for each lambda value.</li> <li>\"mean\": list of mean risk values for each lambda value.</li> <li>\"std\": list of standard deviation of risk values for each lambda value.</li> <li>Additional keys for each parameter in the parameter space.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>The input features.</p> required <code>y</code> <code>ndarray</code> <p>The true labels.</p> required <code>**kwargs</code> <code>dict</code> <p>Additional keyword arguments for risk estimation.</p> <code>{}</code> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If the number of samples in <code>X</code> and <code>y</code> do not match.</p> Source code in <code>risk_control/risk_control.py</code> <pre><code>def evaluate(self, X: np.ndarray, y: np.ndarray, **kwargs) -&gt; None:\n    \"\"\"\n    Evaluate, for all lambda values (i.e., the grid of the decision function),\n    the risk values and means for the given data with respect to the decision\n    function and risk function.\n\n    It sets the `cr_results` attribute with the results of the evaluation.\n    Its a dictionary with the following structure:\n\n    - \"values\": list of risk values for each lambda value.\n    - \"mean\": list of mean risk values for each lambda value.\n    - \"std\": list of standard deviation of risk values for each lambda value.\n    - Additional keys for each parameter in the parameter space.\n\n    Parameters\n    ----------\n    X : np.ndarray\n        The input features.\n    y : np.ndarray\n        The true labels.\n    **kwargs : dict\n        Additional keyword arguments for risk estimation.\n\n    Raises\n    ------\n    AssertionError\n        If the number of samples in `X` and `y` do not match.\n    \"\"\"\n    assert X.shape[0] == y.shape[0]\n    self._n_samples = X.shape[0]\n\n    self.l_values, self.param_shape = self._get_all_combinations(self.params)\n    self.cr_results = self._estimate_risk(X, y, self.l_values, **kwargs)\n</code></pre>"},{"location":"api/risk_control/#risk_control.MapieRiskControl._estimate_pvalues","title":"_estimate_pvalues","text":"<pre><code>_estimate_pvalues(values, alpha, method)\n</code></pre> <p>Estimate p-values for the risk values.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>ndarray</code> <p>The risk values with shape (n_params, n_samples).</p> required <code>alpha</code> <code>float</code> <p>The desired risk value.</p> required <code>method</code> <code>str</code> <p>The method to use for p-value computation (\"clt\" or \"hb\").</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>The computed p-values.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If the method is not in the valid p-values methods.</p> Source code in <code>risk_control/risk_control.py</code> <pre><code>def _estimate_pvalues(\n    self, values: np.ndarray, alpha: float, method: str\n) -&gt; np.ndarray:\n    \"\"\"\n    Estimate p-values for the risk values.\n\n    Parameters\n    ----------\n    values : np.ndarray\n        The risk values with shape (n_params, n_samples).\n    alpha : float\n        The desired risk value.\n    method : str\n        The method to use for p-value computation (\"clt\" or \"hb\").\n\n    Returns\n    -------\n    np.ndarray\n        The computed p-values.\n\n    Raises\n    ------\n    AssertionError\n        If the method is not in the valid p-values methods.\n    \"\"\"\n    assert method in self._valid_pvalues_method\n    p_values = MapieRiskControl._valid_pvalues_method[method](\n        values, alpha, self._n_samples\n    )\n    return np.array(p_values)\n</code></pre>"},{"location":"api/risk_control/#risk_control.MapieRiskControl._control_fwer","title":"_control_fwer","text":"<pre><code>_control_fwer(p_values, delta, method)\n</code></pre> <p>Control the family-wise error rate (FWER).</p> <p>Parameters:</p> Name Type Description Default <code>p_values</code> <code>ndarray</code> <p>The p-values with shape (n_params,).</p> required <code>delta</code> <code>float</code> <p>The desired error rate.</p> required <code>method</code> <code>str</code> <p>The method to use for FWER control (\"standard\" or \"sgt\").</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>The sorted indices of valid hypotheses.</p> <p>Warns:</p> Type Description <code>UserWarning</code> <p>If no valid hypotheses are found.</p> Source code in <code>risk_control/risk_control.py</code> <pre><code>def _control_fwer(\n    self, p_values: np.ndarray, delta: float, method: str\n) -&gt; np.ndarray:\n    \"\"\"\n    Control the family-wise error rate (FWER).\n\n    Parameters\n    ----------\n    p_values : np.ndarray\n        The p-values with shape (n_params,).\n    delta : float\n        The desired error rate.\n    method : str\n        The method to use for FWER control (\"standard\" or \"sgt\").\n\n    Returns\n    -------\n    np.ndarray\n        The sorted indices of valid hypotheses.\n\n    Warns\n    -----\n    UserWarning\n        If no valid hypotheses are found.\n    \"\"\"\n    indexes = MapieRiskControl._valid_fwer_method[method](\n        p_values, delta, self.param_shape\n    )\n\n    if not len(indexes):\n        warnings.warn(\"No valid hypotheses.\")\n        return np.array([])\n    else:\n        return np.sort(indexes)\n</code></pre>"},{"location":"api/risk_control/#risk_control.MapieRiskControl.test","title":"test","text":"<pre><code>test()\n</code></pre> <p>Test all hypotheses and identify valid lambda values that control the risk and family-wise error rate. The procedure is as follows:</p> <ol> <li>Estimate p-values for each lambda (with <code>_estimate_pvalues</code> method).</li> <li>Control the family-wise error rate (with <code>_control_fwer</code> method).</li> <li>Store the valid lambda values (<code>valid_lambdas</code>) and their corresponding risks (<code>valid_risks</code>).</li> </ol> Source code in <code>risk_control/risk_control.py</code> <pre><code>def test(self) -&gt; None:\n    \"\"\"\n    Test all hypotheses and identify valid lambda values that control the\n    risk and family-wise error rate. The procedure is as follows:\n\n    1. Estimate p-values for each lambda (with\n    [`_estimate_pvalues`][risk_control.MapieRiskControl._estimate_pvalues]\n    method).\n    2. Control the family-wise error rate (with\n    [`_control_fwer`][risk_control.MapieRiskControl._control_fwer] method).\n    3. Store the valid lambda values (`valid_lambdas`)\n    and their corresponding risks (`valid_risks`).\n    \"\"\"\n    for name_ in self.risks.keys():\n        self.cr_results[f\"risks.{name_}.p_value\"] = self._estimate_pvalues(\n            values=self.cr_results[f\"risks.{name_}.values\"],\n            alpha=self.target_risks[name_],\n            method=self.pvalue_method,\n        )\n\n    self.cr_specific_results = {}\n    for name_ in self.risks.keys():\n        indexes = self._control_fwer(\n            p_values=self.cr_results[f\"risks.{name_}.p_value\"],\n            delta=self.delta,\n            method=self.fwer_method,\n        )\n        if len(indexes) &gt; 0:\n            self.cr_specific_results[name_] = {\n                \"valid_lambdas\": self.cr_results[\"params\"][indexes],\n                \"valid_risks\": self.cr_results[f\"risks.{name_}.mean\"][indexes],\n                \"p_values\": self.cr_results[f\"risks.{name_}.p_value\"],\n            }\n        else:\n            self.cr_specific_results[name_] = {\n                \"valid_lambdas\": [],\n                \"valid_risks\": [],\n                \"p_values\": self.cr_results[f\"risks.{name_}.p_value\"],\n            }\n\n    p_values = np.array(\n        [self.cr_results[f\"risks.{name_}.p_value\"] for name_ in self.risks.keys()]\n    )\n    p_values = p_values.max(axis=0)\n    self.cr_results[\"risks.AGG.p_value\"] = p_values\n\n    indexes = self._control_fwer(\n        p_values=p_values,\n        delta=self.delta,\n        method=self.fwer_method,\n    )\n\n    self.has_solution = len(indexes) &gt; 0\n\n    if self.has_solution:\n        self.valid_lambdas = self.cr_results[\"params\"][indexes]\n        self.valid_risks = {\n            name_: self.cr_results[f\"risks.{name_}.mean\"][indexes]\n            for name_ in self.risks.keys()\n        }\n    else:\n        self.valid_lambdas = []\n        self.valid_risks = {}\n</code></pre>"},{"location":"api/risk_control/#risk_control.MapieRiskControl.control","title":"control","text":"<pre><code>control()\n</code></pre> <p>Control the risk based on the specified method. The procedure is as follows:</p> <ol> <li>Check if a solution exists (<code>has_solution</code>).</li> <li>If a solution exists, select the optimal lambda value (<code>l_star</code>) and   corresponding risk (<code>r_star</code>) based on the control method.</li> <li>Set the parameters of the decision model to the optimal lambda value.</li> </ol> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no solution is found for risk control.</p> Source code in <code>risk_control/risk_control.py</code> <pre><code>def control(self) -&gt; None:\n    \"\"\"\n    Control the risk based on the specified method. The procedure is as follows:\n\n    1. Check if a solution exists (`has_solution`).\n    2. If a solution exists, select the optimal lambda value (`l_star`) and\n      corresponding risk (`r_star`) based on the control method.\n    3. Set the parameters of the decision model to the optimal lambda value.\n\n    Raises\n    ------\n    ValueError\n        If no solution is found for risk control.\n    \"\"\"\n    if (\n        not self.has_solution\n    ):  # raise ValueError(\"No solution found for risk control.\")\n        self.l_star = None\n        self.r_star = None\n        return\n\n    idx = MapieRiskControl._valid_control_method[self.control_method](self)\n\n    self.l_star: dict[str, float] = self.valid_lambdas[idx]  # type: ignore\n    self.r_star: dict[str, float] = {\n        name_: valid_risks_[idx] for name_, valid_risks_ in self.valid_risks.items()\n    }  # type: ignore\n    if self.l_star:\n        self.decision.set_params(**self.l_star)\n</code></pre>"},{"location":"api/risk_control/#risk_control.MapieRiskControl.fit","title":"fit","text":"<pre><code>fit(X, y, **kwargs)\n</code></pre> <p>Fit the decision model on the input data, i.e.:</p> <ol> <li>Evaluate the decision model on the calibration data.</li> <li>Compute the p-values for the risk control.</li> <li>Find the valid lambdas for the risk control.</li> <li>Find the optimal lambda for the risk control.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>The input features.</p> required <code>y</code> <code>ndarray</code> <p>The target labels.</p> required <code>**kwargs</code> <code>dict</code> <p>Additional keyword arguments to pass to the <code>evaluate</code> method.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>self</code> <code>MapieRiskControl</code> <p>The fitted risk control model.</p> Source code in <code>risk_control/risk_control.py</code> <pre><code>def fit(self, X: np.ndarray, y: np.ndarray, **kwargs):\n    \"\"\"\n    Fit the decision model on the input data, i.e.:\n\n    1. Evaluate the decision model on the calibration data.\n    2. Compute the p-values for the risk control.\n    3. Find the valid lambdas for the risk control.\n    4. Find the optimal lambda for the risk control.\n\n    Parameters\n    ----------\n    X : np.ndarray\n        The input features.\n    y : np.ndarray\n        The target labels.\n    **kwargs : dict\n        Additional keyword arguments to pass to the `evaluate` method.\n\n    Returns\n    -------\n    self : MapieRiskControl\n        The fitted risk control model.\n    \"\"\"\n    self.evaluate(X, y, **kwargs)\n    self.test()\n    self.control()\n    return self\n</code></pre>"},{"location":"api/risk_control/#risk_control.MapieRiskControl.predict","title":"predict","text":"<pre><code>predict(X)\n</code></pre> <p>Make predictions on the input data.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>The input features.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>The predicted labels.</p> Source code in <code>risk_control/risk_control.py</code> <pre><code>def predict(self, X: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Make predictions on the input data.\n\n    Parameters\n    ----------\n    X : np.ndarray\n        The input features.\n\n    Returns\n    -------\n    np.ndarray\n        The predicted labels.\n    \"\"\"\n    return self.decision.predict(X)\n</code></pre>"},{"location":"api/risk_control/#risk_control.MapieRiskControl.summary","title":"summary","text":"<pre><code>summary()\n</code></pre> <p>Print a summary of the risk control results.</p> Source code in <code>risk_control/risk_control.py</code> <pre><code>def summary(self) -&gt; None:\n    \"\"\"\n    Print a summary of the risk control results.\n    \"\"\"\n    print(\"=== SUMMARY ===\")\n    print(\"p(risk&lt;=alpha) &gt;= 1-delta\")\n    print(f\"1-delta: {1 - self.delta:.2f}\")\n    print(\"=== risks ===\")\n    for name_, risk_ in self.risks.items():\n        r_star = (\n            risk_.convert_to_performance(self.r_star[name_])\n            if self.r_star\n            else np.inf\n        )\n        alpha = risk_.convert_to_performance(self.target_risks[name_])\n        print(f\"{name_}\\t| optimal: {r_star:.2f}\\t| alpha: {alpha:.2}\")\n    print(\"=== params ===\")\n    for name_ in self.params.keys():\n        l_star = self.l_star[name_] if self.l_star else np.inf\n        print(f\"{name_}\\t| optimal: {l_star:.2f}\")\n</code></pre>"},{"location":"api/decision/base/","title":"Base Module","text":""},{"location":"api/decision/base/#decision.base","title":"Decision Base Module","text":"<p>Classes:</p> Name Description <code>BaseDecision</code> <p>Abstract base class for decision-making in risk control.</p>"},{"location":"api/decision/base/#decision.base.BaseDecision","title":"BaseDecision","text":"<pre><code>BaseDecision(estimator)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Abstract base class for decision-making in risk control.</p> <p>This class provides a common interface for decision-making algorithms used in risk control. It includes methods for making predictions and decisions.</p>"},{"location":"api/decision/base/#decision.base.BaseDecision--how-does-it-work","title":"How does it work?","text":"<ul> <li>The decision-making algorithm is initialized with an estimator.</li> <li>The estimator is used to make predictions.</li> <li>The decision is made based on the hyper-parameters and the predictions.</li> </ul>"},{"location":"api/decision/base/#decision.base.BaseDecision--how-to-use-it","title":"How to use it?","text":"<ul> <li>Initialize the decision-making algorithm with an estimator and a parameter space.</li> <li>Make predictions using the <code>predict</code> method.<ul> <li>First, the estimator is used to make predictions using the <code>make_prediction</code> method.</li> <li>Then, the decision is made based on the hyper-parameters and the predictions using the <code>make_decision</code> method.</li> </ul> </li> </ul> <p>Parameters:</p> Name Type Description Default <code>estimator</code> <code>BaseEstimator</code> <p>The estimator object used for making predictions.</p> required <p>Attributes:</p> Name Type Description <code>estimator</code> <code>BaseEstimator</code> <p>The estimator object used for making predictions.</p> <p>Methods:</p> Name Description <code>set_params</code> <p>Set the parameters of the estimator.</p> <code>get_params</code> <p>Get the parameters of the estimator.</p> <code>make_prediction</code> <p>Abstract method for predicting output values based on the input data.</p> <code>make_decision</code> <p>Abstract method for predicting decisions based on output values.</p> <code>predict</code> <p>Predict decisions based on the input data.</p> <code>fit</code> <p>Fit the estimator to the input data.</p> Source code in <code>risk_control/decision/base.py</code> <pre><code>def __init__(self, estimator: BaseEstimator) -&gt; None:\n    self.estimator = estimator\n</code></pre>"},{"location":"api/decision/base/#decision.base.BaseDecision.estimator","title":"estimator  <code>instance-attribute</code>","text":"<pre><code>estimator = estimator\n</code></pre>"},{"location":"api/decision/base/#decision.base.BaseDecision.set_params","title":"set_params","text":"<pre><code>set_params(**params)\n</code></pre> <p>Set the parameters of the estimator.</p> <p>Parameters:</p> Name Type Description Default <code>**params</code> <code>dict</code> <p>The parameters to set on the estimator.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>self</code> <code>BaseDecision</code> <p>Returns the instance itself.</p> Source code in <code>risk_control/decision/base.py</code> <pre><code>def set_params(self, **params):\n    \"\"\"\n    Set the parameters of the estimator.\n\n    Parameters\n    ----------\n    **params : dict\n        The parameters to set on the estimator.\n\n    Returns\n    -------\n    self : BaseDecision\n        Returns the instance itself.\n    \"\"\"\n    for key, value in params.items():\n        setattr(self, key, value)\n    return self\n</code></pre>"},{"location":"api/decision/base/#decision.base.BaseDecision.get_params","title":"get_params  <code>abstractmethod</code>","text":"<pre><code>get_params()\n</code></pre> <p>Get the parameters of the estimator.</p> <p>Returns:</p> Name Type Description <code>params</code> <code>dict</code> <p>The parameters of the estimator.</p> Source code in <code>risk_control/decision/base.py</code> <pre><code>@abstractmethod\ndef get_params(self) -&gt; dict:\n    \"\"\"\n    Get the parameters of the estimator.\n\n    Returns\n    -------\n    params : dict\n        The parameters of the estimator.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/decision/base/#decision.base.BaseDecision.make_prediction","title":"make_prediction  <code>abstractmethod</code>","text":"<pre><code>make_prediction(X)\n</code></pre> <p>Abstract method for predicting output values based on the input data.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>The input data for making predictions.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The predicted output values based on the input data.</p> Source code in <code>risk_control/decision/base.py</code> <pre><code>@abstractmethod\ndef make_prediction(self, X: np.ndarray) -&gt; Any:\n    \"\"\"\n    Abstract method for predicting output values based on the input data.\n\n    Parameters\n    ----------\n    X : np.ndarray\n        The input data for making predictions.\n\n    Returns\n    -------\n    Any\n        The predicted output values based on the input data.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/decision/base/#decision.base.BaseDecision.make_decision","title":"make_decision  <code>abstractmethod</code>","text":"<pre><code>make_decision(y_output)\n</code></pre> <p>Abstract method for predicting decisions based on output values.</p> <p>Parameters:</p> Name Type Description Default <code>y_output</code> <code>Any</code> <p>The predicted output values.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>The predicted decisions based on the output values.</p> Source code in <code>risk_control/decision/base.py</code> <pre><code>@abstractmethod\ndef make_decision(self, y_output: Any) -&gt; np.ndarray:\n    \"\"\"\n    Abstract method for predicting decisions based on output values.\n\n    Parameters\n    ----------\n    y_output : Any\n        The predicted output values.\n\n    Returns\n    -------\n    np.ndarray\n        The predicted decisions based on the output values.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/decision/base/#decision.base.BaseDecision.predict","title":"predict","text":"<pre><code>predict(X)\n</code></pre> <p>Predict decisions based on the input data.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>The input data for making predictions.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>The predicted decisions based on the input data.</p> Source code in <code>risk_control/decision/base.py</code> <pre><code>def predict(self, X: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Predict decisions based on the input data.\n\n    Parameters\n    ----------\n    X : np.ndarray\n        The input data for making predictions.\n\n    Returns\n    -------\n    np.ndarray\n        The predicted decisions based on the input data.\n    \"\"\"\n    y_output = self.make_prediction(X)\n    y_decision = self.make_decision(y_output)\n    return y_decision\n</code></pre>"},{"location":"api/decision/base/#decision.base.BaseDecision.fit","title":"fit","text":"<pre><code>fit(X, y)\n</code></pre> <p>Fit the estimator to the input data.</p> <p>This method is a placeholder and does not perform any fitting. It is intended to be overridden by subclasses that require fitting.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>The input data for fitting the estimator.</p> required <code>y</code> <code>ndarray</code> <p>The target values for fitting the estimator.</p> required <p>Returns:</p> Name Type Description <code>self</code> <code>BaseDecision</code> <p>Returns the instance itself.</p> Source code in <code>risk_control/decision/base.py</code> <pre><code>def fit(self, X: np.ndarray, y: np.ndarray):\n    \"\"\"\n    Fit the estimator to the input data.\n\n    This method is a placeholder and does not perform any fitting. It is\n    intended to be overridden by subclasses that require fitting.\n\n    Parameters\n    ----------\n    X : np.ndarray\n        The input data for fitting the estimator.\n    y : np.ndarray\n        The target values for fitting the estimator.\n\n    Returns\n    -------\n    self : BaseDecision\n        Returns the instance itself.\n    \"\"\"\n    return self\n</code></pre>"},{"location":"api/decision/classification/","title":"Classification Module","text":""},{"location":"api/decision/classification/#decision.classification","title":"Classification Module","text":"<p>Classes:</p> Name Description <code>BaseClassificationDecision</code> <p>Base class for classification-based decision-making.</p>"},{"location":"api/decision/classification/#decision.classification.BaseClassificationDecision","title":"BaseClassificationDecision","text":"<pre><code>BaseClassificationDecision(\n    estimator,\n    *,\n    threshold=0.0,\n    toto=0.0,\n    predict_mode=\"score\"\n)\n</code></pre> <p>               Bases: <code>BaseDecision</code>, <code>ABC</code></p> <p>Base class for classification-based decision-making.</p> <p>This class provides a common interface for classification-based decision-making algorithms.</p> <p>It calls <code>estimator.predict_proba(X)</code> or <code>estimator.decision_function(X)</code> to predict the output values.</p>"},{"location":"api/decision/classification/#decision.classification.BaseClassificationDecision--when-using-this-class","title":"When using this class?","text":"<ul> <li>When the decision is based on the output of a classification model.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>estimator</code> <code>BaseEstimator</code> <p>The estimator object used for making predictions.</p> required <code>threshold</code> <code>float</code> <p>The threshold value used for decision-making.</p> <code>0.0</code> <code>predict_mode</code> <code>str</code> <p>The mode to use for prediction. Can be 'proba' or 'score'.</p> <code>'score'</code> <p>Attributes:</p> Name Type Description <code>estimator</code> <code>BaseEstimator</code> <p>The estimator object used for making predictions.</p> <code>threshold</code> <code>float</code> <p>The threshold value used for decision-making.</p> <code>predict_mode</code> <code>str</code> <p>The mode to use for prediction. Can be 'proba' or 'score'.</p> <ul> <li>If 'proba', the <code>predict_proba</code> method of the estimator is used.</li> <li>If 'score', the <code>decision_function</code> method of the estimator is used.</li> </ul> <p>Methods:</p> Name Description <code>get_params</code> <p>Get the parameters of the estimator.</p> <code>make_prediction</code> <p>Predict the output values based on the input data.</p> Source code in <code>risk_control/decision/classification.py</code> <pre><code>def __init__(\n    self,\n    estimator: BaseEstimator,\n    *,\n    threshold: float = 0.0,\n    toto: float = 0.0,\n    predict_mode: str = \"score\",\n) -&gt; None:\n    super().__init__(estimator=estimator)\n    self.threshold = threshold\n    self.toto = toto\n    self.predict_mode = predict_mode\n</code></pre>"},{"location":"api/decision/classification/#decision.classification.BaseClassificationDecision.threshold","title":"threshold  <code>instance-attribute</code>","text":"<pre><code>threshold = threshold\n</code></pre>"},{"location":"api/decision/classification/#decision.classification.BaseClassificationDecision.toto","title":"toto  <code>instance-attribute</code>","text":"<pre><code>toto = toto\n</code></pre>"},{"location":"api/decision/classification/#decision.classification.BaseClassificationDecision.predict_mode","title":"predict_mode  <code>instance-attribute</code>","text":"<pre><code>predict_mode = predict_mode\n</code></pre>"},{"location":"api/decision/classification/#decision.classification.BaseClassificationDecision.get_params","title":"get_params","text":"<pre><code>get_params()\n</code></pre> <p>Get the parameters of the estimator.</p> <p>Returns:</p> Name Type Description <code>params</code> <code>dict</code> <p>The parameters of the estimator.</p> Source code in <code>risk_control/decision/classification.py</code> <pre><code>def get_params(self):\n    \"\"\"\n    Get the parameters of the estimator.\n\n    Returns\n    -------\n    params : dict\n        The parameters of the estimator.\n    \"\"\"\n    return super().get_params() | {\n        \"threshold\": self.threshold,\n        \"toto\": self.toto,\n        \"predict_mode\": self.predict_mode,\n    }\n</code></pre>"},{"location":"api/decision/classification/#decision.classification.BaseClassificationDecision.make_prediction","title":"make_prediction","text":"<pre><code>make_prediction(X)\n</code></pre> <p>Predict the output values based on the input data.</p> <ul> <li>If predict_mode is 'proba', return the predicted probabilities.</li> <li>If predict_mode is 'score', return the decision function scores.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>The input data for making predictions.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>The predicted output values based on the input data.</p> Source code in <code>risk_control/decision/classification.py</code> <pre><code>def make_prediction(self, X: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Predict the output values based on the input data.\n\n    - If predict_mode is 'proba', return the predicted probabilities.\n    - If predict_mode is 'score', return the decision function scores.\n\n    Parameters\n    ----------\n    X : np.ndarray\n        The input data for making predictions.\n\n    Returns\n    -------\n    np.ndarray\n        The predicted output values based on the input data.\n    \"\"\"\n    assert self.predict_mode in [\n        \"proba\",\n        \"score\",\n    ], \"predict_mode must be 'proba' or 'score'\"\n    if self.predict_mode == \"proba\":\n        return self.estimator.predict_proba(X)\n    elif self.predict_mode == \"score\":\n        return self.estimator.decision_function(X)\n    else:\n        return self.estimator.predict(X)\n</code></pre>"},{"location":"api/decision/examples/","title":"Examples of Implementation","text":""},{"location":"api/decision/examples/#decision.decision","title":"Implementations","text":"<p>Classes:</p> Name Description <code>SelectiveRegression</code> <p>Selective regression-based decision-making.</p> <code>SelectiveClassification</code> <p>Selective classification-based decision-making.</p> <code>SelectiveClassificationV2</code> <p>Selective classification-based decision-making.</p> <code>MultiSelectiveClassification</code> <p>Selective classification-based decision-making.</p>"},{"location":"api/decision/examples/#decision.decision.SelectiveRegression","title":"SelectiveRegression","text":"<p>               Bases: <code>AdvancedRegressionDecision</code></p> <p>Selective regression-based decision-making.</p> <ol> <li>Predict the estimated prediction and residual using two separate estimators.</li> <li>If the residual is less than or equal to the threshold,     return the prediction; otherwise, NaN.</li> </ol>"},{"location":"api/decision/examples/#decision.decision.SelectiveRegression--when-using-this-class","title":"When using this class?","text":"<ul> <li>When the prediction and residual are estimated separately.</li> <li>When the decision is based on the residual.</li> <li>When you want to select predictions with low residuals.</li> <li>When you want to deleguate the decision to a human operator when the confidence is low.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>estimator</code> <code>BaseEstimator</code> <p>The estimator used to predict the output values.</p> required <code>residual</code> <code>BaseEstimator</code> <p>The estimator used to predict the residuals.</p> required <code>threshold</code> <code>float</code> <p>The threshold for the residual. If the residual is less than or equal to the threshold, the prediction is returned; otherwise, NaN. The default is 0.0.</p> required <p>Attributes:</p> Name Type Description <code>estimator</code> <code>BaseEstimator</code> <p>The estimator used to predict the output values.</p> <code>residual</code> <code>BaseEstimator</code> <p>The estimator used to predict the residuals.</p> <code>threshold</code> <code>float</code> <p>The threshold for the residual.</p> <p>Methods:</p> Name Description <code>make_decision</code> <p>Predict the decision for the input data based on the output values</p>"},{"location":"api/decision/examples/#decision.decision.SelectiveRegression.make_decision","title":"make_decision","text":"<pre><code>make_decision(y_output)\n</code></pre> <p>Predict the decision for the input data based on the output values and residuals.</p> <p>Parameters:</p> Name Type Description Default <code>y_output</code> <code>Tuple[ndarray, ndarray]</code> <p>The output values and residuals for the input data. The first element is the output values, and the second element is the residuals</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>The predicted decision for the input data. The decision is made based on the output values and residuals. If the residual is less than or equal to the threshold, the decision is the output value; otherwise, the decision is NaN.</p> Source code in <code>risk_control/decision/decision.py</code> <pre><code>def make_decision(self, y_output: Tuple[np.ndarray, np.ndarray]) -&gt; np.ndarray:\n    \"\"\"\n    Predict the decision for the input data based on the output values\n    and residuals.\n\n    Parameters\n    ----------\n    y_output : Tuple[np.ndarray, np.ndarray]\n        The output values and residuals for the input data.\n        The first element is the output values, and the second element is\n        the residuals\n\n    Returns\n    -------\n    np.ndarray\n        The predicted decision for the input data.\n        The decision is made based on the output values and residuals.\n        If the residual is less than or equal to the threshold, the decision is\n        the output value; otherwise, the decision is NaN.\n    \"\"\"\n    y_pred, y_res = y_output\n    y_post = np.where(\n        y_res &lt;= self.threshold, y_pred, np.empty_like(y_pred) * (np.nan)\n    )\n    return y_post\n</code></pre>"},{"location":"api/decision/examples/#decision.decision.SelectiveClassification","title":"SelectiveClassification","text":"<p>               Bases: <code>BaseClassificationDecision</code></p> <p>Selective classification-based decision-making.</p> <ol> <li>Predict the estimated probability or score using the estimator.</li> <li>If the probability or score of the top-1 class is greater than or equal to     the threshold, return the top-1 class; otherwise, return NaN.</li> </ol>"},{"location":"api/decision/examples/#decision.decision.SelectiveClassification--when-using-this-class","title":"When using this class?","text":"<ul> <li>When you want to select the top-1 class with high confidence.</li> <li>When you want to control the false discovery rate.</li> <li>When you want to deleguate the decision to a human operator when the confidence is low.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>estimator</code> <code>BaseEstimator</code> <p>The estimator object used for making predictions.</p> required <code>threshold</code> <code>float</code> <p>The threshold value used for decision-making.</p> required <code>predict_mode</code> <code>str</code> <p>The mode to use for prediction. Can be 'proba' or 'score'.</p> required <p>Attributes:</p> Name Type Description <code>estimator</code> <code>BaseEstimator</code> <p>The estimator object used for making predictions.</p> <code>threshold</code> <code>float</code> <p>The threshold value used for decision-making.</p> <code>predict_mode</code> <code>str</code> <p>The mode to use for prediction. Can be 'proba' or 'score'.</p> <p>Methods:</p> Name Description <code>make_decision</code> <p>Predict the decision for the input data based on the output values.</p>"},{"location":"api/decision/examples/#decision.decision.SelectiveClassification.make_decision","title":"make_decision","text":"<pre><code>make_decision(y_output)\n</code></pre> <p>Predict the decision for the input data based on the output values.</p> <p>Parameters:</p> Name Type Description Default <code>y_output</code> <code>ndarray</code> <p>The output values predicted by the estimator.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>The predicted decisions based on the output values and threshold.</p> Source code in <code>risk_control/decision/decision.py</code> <pre><code>def make_decision(self, y_output: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Predict the decision for the input data based on the output values.\n\n    Parameters\n    ----------\n    y_output : np.ndarray\n        The output values predicted by the estimator.\n\n    Returns\n    -------\n    np.ndarray\n        The predicted decisions based on the output values and threshold.\n    \"\"\"\n    n_samples, n_classes = y_output.shape\n\n    best_score_idx = np.argmax(y_output, axis=1)\n    y_post = np.zeros((n_samples, n_classes), dtype=bool)\n    y_post[np.arange(n_samples), best_score_idx] = y_output[\n        np.arange(n_samples), best_score_idx\n    ] &gt;= max(self.threshold, self.toto)\n\n    return y_post\n</code></pre>"},{"location":"api/decision/examples/#decision.decision.SelectiveClassificationV2","title":"SelectiveClassificationV2","text":"<p>               Bases: <code>BaseClassificationDecision</code></p> <p>Selective classification-based decision-making.</p> <ol> <li>Predict the estimated probability or score using the estimator.</li> <li>If the probability or score of the top-1 class is greater than or equal to     the threshold, return the top-1 class; otherwise, return NaN.</li> </ol>"},{"location":"api/decision/examples/#decision.decision.SelectiveClassificationV2--when-using-this-class","title":"When using this class?","text":"<ul> <li>When you want to select the top-1 class with high confidence.</li> <li>When you want to control the false discovery rate.</li> <li>When you want to deleguate the decision to a human operator when the confidence is low.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>estimator</code> <code>BaseEstimator</code> <p>The estimator object used for making predictions.</p> required <code>threshold</code> <code>float</code> <p>The threshold value used for decision-making.</p> required <code>predict_mode</code> <code>str</code> <p>The mode to use for prediction. Can be 'proba' or 'score'.</p> required <p>Attributes:</p> Name Type Description <code>estimator</code> <code>BaseEstimator</code> <p>The estimator object used for making predictions.</p> <code>threshold</code> <code>float</code> <p>The threshold value used for decision-making.</p> <code>predict_mode</code> <code>str</code> <p>The mode to use for prediction. Can be 'proba' or 'score'.</p> <p>Methods:</p> Name Description <code>make_decision</code> <p>Predict the decision for the input data based on the output values.</p>"},{"location":"api/decision/examples/#decision.decision.SelectiveClassificationV2.make_decision","title":"make_decision","text":"<pre><code>make_decision(y_output)\n</code></pre> <p>Predict the decision for the input data based on the output values.</p> <p>Parameters:</p> Name Type Description Default <code>y_output</code> <code>ndarray</code> <p>The output values predicted by the estimator.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>The predicted decisions based on the output values and threshold.</p> Source code in <code>risk_control/decision/decision.py</code> <pre><code>def make_decision(self, y_output: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Predict the decision for the input data based on the output values.\n\n    Parameters\n    ----------\n    y_output : np.ndarray\n        The output values predicted by the estimator.\n\n    Returns\n    -------\n    np.ndarray\n        The predicted decisions based on the output values and threshold.\n    \"\"\"\n    y_idx = np.argmax(y_output, axis=1)\n    y_score = np.max(y_output, axis=1)\n    y_post = np.where(\n        y_score &gt;= self.threshold, y_idx, np.empty_like(y_idx) * (np.nan)\n    )\n    return y_post\n</code></pre>"},{"location":"api/decision/examples/#decision.decision.MultiSelectiveClassification","title":"MultiSelectiveClassification","text":"<p>               Bases: <code>BaseClassificationDecision</code></p> <p>Selective classification-based decision-making.</p> <ol> <li>Predict the estimated probability or score using the estimator.</li> <li>If the probability or score of any class is greater than or equal to the     threshold, return True; otherwise, return False.</li> </ol>"},{"location":"api/decision/examples/#decision.decision.MultiSelectiveClassification--when-using-this-class","title":"When using this class?","text":"<ul> <li>When you want to select best candidates with high confidence.</li> <li>When you want to deleguate the decision to a human operator when the confidence is low.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>estimator</code> <code>BaseEstimator</code> <p>The estimator object used for making predictions.</p> required <code>threshold</code> <code>float</code> <p>The threshold value used for decision-making.</p> required <code>predict_mode</code> <code>str</code> <p>The mode to use for prediction. Can be 'proba' or 'score'.</p> required <p>Attributes:</p> Name Type Description <code>estimator</code> <code>BaseEstimator</code> <p>The estimator object used for making predictions.</p> <code>threshold</code> <code>float</code> <p>The threshold value used for decision-making.</p> <code>predict_mode</code> <code>str</code> <p>The mode to use for prediction. Can be 'proba' or 'score'.</p> <p>Methods:</p> Name Description <code>make_decision</code> <p>Predict the decision for the input data based on the output values.</p>"},{"location":"api/decision/examples/#decision.decision.MultiSelectiveClassification.make_decision","title":"make_decision","text":"<pre><code>make_decision(y_output)\n</code></pre> <p>Predict the decision for the input data based on the output values.</p> <p>Parameters:</p> Name Type Description Default <code>y_output</code> <code>ndarray</code> <p>The output values predicted by the estimator.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>The predicted decisions based on the output values and threshold.</p> Source code in <code>risk_control/decision/decision.py</code> <pre><code>def make_decision(self, y_output: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Predict the decision for the input data based on the output values.\n\n    Parameters\n    ----------\n    y_output : np.ndarray\n        The output values predicted by the estimator.\n\n    Returns\n    -------\n    np.ndarray\n        The predicted decisions based on the output values and threshold.\n    \"\"\"\n    y_post = y_output &gt;= self.threshold\n    return y_post\n</code></pre>"},{"location":"api/decision/regression/","title":"Regression Module","text":""},{"location":"api/decision/regression/#decision.regression","title":"Regression Module","text":"<p>Classes:</p> Name Description <code>BaseRegressionDecision</code> <p>Base class for regression-based decision-making.</p> <code>AdvancedRegressionDecision</code> <p>Advanced class for regression-based decision-making.</p>"},{"location":"api/decision/regression/#decision.regression.BaseRegressionDecision","title":"BaseRegressionDecision","text":"<pre><code>BaseRegressionDecision(estimator, *, threshold=0.0)\n</code></pre> <p>               Bases: <code>BaseDecision</code>, <code>ABC</code></p> <p>Base class for regression-based decision-making.</p> <p>This class provides a common interface for regression-based decision-making algorithms.</p> <p>It calls <code>estimator.predict(X)</code> to predict the output values.</p>"},{"location":"api/decision/regression/#decision.regression.BaseRegressionDecision--when-using-this-class","title":"When using this class?","text":"<ul> <li>When the decision is based on the output of a regression model.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>estimator</code> <code>BaseEstimator</code> <p>The estimator used to predict the output values.</p> required <code>threshold</code> <code>float</code> <p>The threshold for the prediction. If the prediction is less than or equal to the threshold, the decision is NaN; otherwise, the prediction.</p> <code>0.0</code> <p>Attributes:</p> Name Type Description <code>estimator</code> <code>BaseEstimator</code> <p>The estimator used to predict the output values.</p> <code>threshold</code> <code>float</code> <p>The threshold for the residual.</p> <p>Methods:</p> Name Description <code>get_params</code> <p>Get the parameters of the estimator.</p> <code>make_prediction</code> <p>Predict the output values based on the input data.</p> Source code in <code>risk_control/decision/regression.py</code> <pre><code>def __init__(\n    self,\n    estimator: BaseEstimator,\n    *,\n    threshold: float = 0.0,\n) -&gt; None:\n    super().__init__(estimator)\n    self.threshold = threshold\n</code></pre>"},{"location":"api/decision/regression/#decision.regression.BaseRegressionDecision.threshold","title":"threshold  <code>instance-attribute</code>","text":"<pre><code>threshold = threshold\n</code></pre>"},{"location":"api/decision/regression/#decision.regression.BaseRegressionDecision.get_params","title":"get_params","text":"<pre><code>get_params()\n</code></pre> <p>Get the parameters of the estimator.</p> <p>Returns:</p> Name Type Description <code>params</code> <code>dict</code> <p>The parameters of the estimator.</p> Source code in <code>risk_control/decision/regression.py</code> <pre><code>def get_params(self):\n    \"\"\"\n    Get the parameters of the estimator.\n\n    Returns\n    -------\n    params : dict\n        The parameters of the estimator.\n    \"\"\"\n    return super().get_params() | {\"threshold\": self.threshold}\n</code></pre>"},{"location":"api/decision/regression/#decision.regression.BaseRegressionDecision.make_prediction","title":"make_prediction","text":"<pre><code>make_prediction(X)\n</code></pre> <p>Predict the output values based on the input data.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>The input data for making predictions.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>The predicted output values based on the input data.</p> Source code in <code>risk_control/decision/regression.py</code> <pre><code>def make_prediction(self, X: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Predict the output values based on the input data.\n\n    Parameters\n    ----------\n    X : np.ndarray\n        The input data for making predictions.\n\n    Returns\n    -------\n    np.ndarray\n        The predicted output values based on the input data.\n    \"\"\"\n    return self.estimator.predict(X)\n</code></pre>"},{"location":"api/decision/regression/#decision.regression.AdvancedRegressionDecision","title":"AdvancedRegressionDecision","text":"<pre><code>AdvancedRegressionDecision(\n    estimator, residual, *, threshold=1.0\n)\n</code></pre> <p>               Bases: <code>BaseDecision</code>, <code>ABC</code></p> <p>Advanced class for regression-based decision-making.</p> <p>This class provides a common interface for regression-based decision-making algorithms based on residuals.</p> <p>It calls <code>estimator.predict(X)</code> to predict the output values and <code>residual.predict(X)</code> to predict the residuals.</p>"},{"location":"api/decision/regression/#decision.regression.AdvancedRegressionDecision--when-using-this-class","title":"When using this class?","text":"<ul> <li>When the prediction and residual are estimated separately.</li> <li>When the decision is based on the residual.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>estimator</code> <code>BaseEstimator</code> <p>The estimator used to predict the output values.</p> required <code>residual</code> <code>BaseEstimator</code> <p>The estimator used to predict the residuals.</p> required <code>threshold</code> <code>float</code> <p>The threshold for the residual. If the residual is less than or equal to the threshold, the prediction is returned; otherwise, NaN. The default is 0.0.</p> <code>1.0</code> <p>Attributes:</p> Name Type Description <code>estimator</code> <code>BaseEstimator</code> <p>The estimator used to predict the output values.</p> <code>residual</code> <code>BaseEstimator</code> <p>The estimator used to predict the residuals.</p> <code>threshold</code> <code>float</code> <p>The threshold for the residual.</p> <p>Methods:</p> Name Description <code>get_params</code> <p>Get the parameters of the estimator.</p> <code>make_prediction</code> <p>Predict the output values and residuals for the input data.</p> Source code in <code>risk_control/decision/regression.py</code> <pre><code>def __init__(\n    self,\n    estimator: BaseEstimator,\n    residual: BaseEstimator,\n    *,\n    threshold: float = 1.0,\n) -&gt; None:\n    super().__init__(estimator)\n    self.residual = residual\n    self.threshold = threshold\n</code></pre>"},{"location":"api/decision/regression/#decision.regression.AdvancedRegressionDecision.residual","title":"residual  <code>instance-attribute</code>","text":"<pre><code>residual = residual\n</code></pre>"},{"location":"api/decision/regression/#decision.regression.AdvancedRegressionDecision.threshold","title":"threshold  <code>instance-attribute</code>","text":"<pre><code>threshold = threshold\n</code></pre>"},{"location":"api/decision/regression/#decision.regression.AdvancedRegressionDecision.get_params","title":"get_params","text":"<pre><code>get_params()\n</code></pre> <p>Get the parameters of the estimator.</p> <p>Returns:</p> Name Type Description <code>params</code> <code>dict</code> <p>The parameters of the estimator.</p> Source code in <code>risk_control/decision/regression.py</code> <pre><code>def get_params(self):\n    \"\"\"\n    Get the parameters of the estimator.\n\n    Returns\n    -------\n    params : dict\n        The parameters of the estimator.\n    \"\"\"\n    return super().get_params() | {\"threshold\": self.threshold}\n</code></pre>"},{"location":"api/decision/regression/#decision.regression.AdvancedRegressionDecision.make_prediction","title":"make_prediction","text":"<pre><code>make_prediction(X)\n</code></pre> <p>Predict the output values and residuals for the input data.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>The input data for which to predict the output values and residuals.</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>The predicted output values and residuals. The first element is the predicted output values, and the second element is the predicted residuals.</p> Source code in <code>risk_control/decision/regression.py</code> <pre><code>def make_prediction(self, X: np.ndarray) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Predict the output values and residuals for the input data.\n\n    Parameters\n    ----------\n    X : np.ndarray\n        The input data for which to predict the output values and residuals.\n\n    Returns\n    -------\n    Tuple[np.ndarray, np.ndarray]\n        The predicted output values and residuals.\n        The first element is the predicted output values, and the second element\n        is the predicted residuals.\n    \"\"\"\n    return self.estimator.predict(X), self.residual.predict(X)\n</code></pre>"},{"location":"api/tools/fwer_control/","title":"FWER Control","text":""},{"location":"api/tools/fwer_control/#tools.fwer_control","title":"FWER Control Utilities","text":"<p>Functions:</p> Name Description <code>fwer_bonferroni</code> <p>Perform Bonferroni correction for multiple testing.</p> <code>fwer_sgt</code> <p>Perform Sequential Graphical Testing (SGT) for multiple testing.</p> <code>fwer_sgt_nd</code> <p>Perform Sequential Graphical Testing (SGT) for multiple testing on n-dimensional p-values.</p> <code>get_neighbors</code> <p>Get the neighbors of a given index in an n-dimensional array.</p>"},{"location":"api/tools/fwer_control/#tools.fwer_control.fwer_bonferroni","title":"fwer_bonferroni","text":"<pre><code>fwer_bonferroni(p_values, delta)\n</code></pre> <p>Perform Bonferroni correction for multiple testing.</p> <p>This function adjusts the significance level (delta) for multiple comparisons using the Bonferroni correction method. It divides the significance level by the number of comparisons to control the family-wise error rate (FWER).</p> <p>Parameters:</p> Name Type Description Default <code>p_values</code> <code>ndarray</code> <p>Array of p-values from individual hypothesis testing.</p> required <code>delta</code> <code>float</code> <p>Desired upper bound on the family-wise error rate.</p> required <p>Returns:</p> Name Type Description <code>lambda_indexes</code> <code>ndarray</code> <p>Indices of p-values that are less than or equal to the adjusted significance level (delta).</p> Source code in <code>risk_control/tools/fwer_control.py</code> <pre><code>def fwer_bonferroni(p_values: np.ndarray, delta: float) -&gt; np.ndarray:\n    \"\"\"\n    Perform Bonferroni correction for multiple testing.\n\n    This function adjusts the significance level (delta) for multiple\n    comparisons using the Bonferroni correction method. It divides the\n    significance level by the number of comparisons to control the\n    family-wise error rate (FWER).\n\n    Parameters\n    ----------\n    p_values : np.ndarray\n        Array of p-values from individual hypothesis testing.\n    delta : float\n        Desired upper bound on the family-wise error rate.\n\n    Returns\n    -------\n    lambda_indexes : np.ndarray\n        Indices of p-values that are less than or equal to the adjusted\n        significance level (delta).\n    \"\"\"\n    new_delta = delta / len(p_values)\n    lambda_indexes = np.where(p_values &lt;= new_delta)[0]\n    return lambda_indexes\n</code></pre>"},{"location":"api/tools/fwer_control/#tools.fwer_control.fwer_sgt","title":"fwer_sgt","text":"<pre><code>fwer_sgt(p_values, delta)\n</code></pre> <p>Perform Sequential Graphical Testing (SGT) for multiple testing.</p> <p>This function implements the SGT procedure with FWER control, which sequentially tests hypotheses and adjusts the significance level to control the family-wise error rate (FWER).</p> <p>It works by iteratively testing the smallest p-value, rejecting the corresponding hypothesis if it is smaller than the current significance level, and adjusting the significance level for the remaining tests until no more hypotheses can be rejected.</p> <p>Parameters:</p> Name Type Description Default <code>p_values</code> <code>ndarray</code> <p>Array of p-values from individual hypothesis tests.</p> required <code>delta</code> <code>float</code> <p>Desired upper bound on the family-wise error rate.</p> required <p>Returns:</p> Name Type Description <code>lambda_indexes</code> <code>ndarray</code> <p>List of indices of the hypotheses that are rejected by the SGT procedure.</p> Source code in <code>risk_control/tools/fwer_control.py</code> <pre><code>def fwer_sgt(p_values: np.ndarray, delta: float) -&gt; np.ndarray:\n    \"\"\"\n    Perform Sequential Graphical Testing (SGT) for multiple testing.\n\n    This function implements the SGT procedure with FWER control, which\n    sequentially tests hypotheses and adjusts the significance level to\n    control the family-wise error rate (FWER).\n\n    It works by iteratively testing the smallest p-value, rejecting the\n    corresponding hypothesis if it is smaller than the current significance level,\n    and adjusting the significance level for the remaining tests until no more\n    hypotheses can be rejected.\n\n    Parameters\n    ----------\n    p_values : np.ndarray\n        Array of p-values from individual hypothesis tests.\n    delta : float\n        Desired upper bound on the family-wise error rate.\n\n    Returns\n    -------\n    lambda_indexes : np.ndarray\n        List of indices of the hypotheses that are rejected by the SGT procedure.\n    \"\"\"\n    # pi: list of p-values\n    pi: list[float] = p_values.tolist()\n    # di: list of significance levels\n    di: list[float] = [delta / len(p_values)] * len(p_values)\n    # lambda_indexes: list of indices of the hypotheses that are rejected\n    lambda_indexes = []\n    init_indexes = list(range(len(p_values)))\n    idx = np.argmin(pi)\n\n    # while the smallest p-value is smaller than the current significance level\n    while pi[idx] &lt;= di[idx]:\n        # remove the hypothesis from the list of hypotheses to test\n        # d = di[idx]\n        # pi[idx], di[idx] = np.inf, 0\n        _, d, old_idx = pi.pop(idx), di.pop(idx), init_indexes.pop(idx)\n\n        # add the hypothesis to the list of rejected hypotheses\n        lambda_indexes.append(old_idx)\n\n        # adjust the significance levels for the remaining hypotheses\n        if idx == 0:\n            di[0] += d\n        elif idx == len(di):\n            di[-1] += d\n        else:\n            di[idx] += d / 2\n            di[idx - 1] += d / 2\n\n        idx = np.argmin(pi)\n        np.testing.assert_approx_equal(delta, np.sum(di))\n\n    lambda_indexes = np.array(lambda_indexes)\n\n    return lambda_indexes\n</code></pre>"},{"location":"api/tools/fwer_control/#tools.fwer_control.fwer_sgt_nd","title":"fwer_sgt_nd","text":"<pre><code>fwer_sgt_nd(p_values, delta, param_shape)\n</code></pre> <p>Perform Sequential Graphical Testing (SGT) for multiple testing on n-dimensional p-values.</p> <p>This function implements the SGT procedure with FWER control for n-dimensional p-values. It sequentially tests hypotheses and adjusts the significance level to control the family-wise error rate (FWER).</p> <p>Parameters:</p> Name Type Description Default <code>p_values</code> <code>ndarray</code> <p>n-dimensional array of p-values from individual hypothesis tests.</p> required <code>delta</code> <code>float</code> <p>Desired upper bound on the family-wise error rate.</p> required <code>param_shape</code> <code>tuple</code> <p>Shape of the parameter grid.</p> required <p>Returns:</p> Name Type Description <code>lambda_indexes</code> <code>ndarray</code> <p>List of indices of the hypotheses that are rejected by the SGT procedure.</p> Source code in <code>risk_control/tools/fwer_control.py</code> <pre><code>def fwer_sgt_nd(p_values: np.ndarray, delta: float, param_shape: tuple) -&gt; np.ndarray:\n    \"\"\"\n    Perform Sequential Graphical Testing (SGT) for multiple testing on n-dimensional p-values.\n\n    This function implements the SGT procedure with FWER control for n-dimensional\n    p-values. It sequentially tests hypotheses and adjusts the significance level\n    to control the family-wise error rate (FWER).\n\n    Parameters\n    ----------\n    p_values : np.ndarray\n        n-dimensional array of p-values from individual hypothesis tests.\n    delta : float\n        Desired upper bound on the family-wise error rate.\n    param_shape : tuple\n        Shape of the parameter grid.\n\n    Returns\n    -------\n    lambda_indexes : np.ndarray\n        List of indices of the hypotheses that are rejected by the SGT procedure.\n    \"\"\"\n    # Flatten the p-values array to a 1D list for easier manipulation\n    pi = p_values.flatten().tolist()\n    # Initialize the significance levels for each hypothesis\n    di = [delta / p_values.size] * p_values.size\n    # List to store the indices of rejected hypotheses\n    lambda_indexes = []\n    # Find the index of the smallest p-value\n    idx = np.argmin(pi)\n\n    # While the smallest p-value is smaller than the current significance level\n    while pi[idx] &lt;= di[idx]:\n        # Remove the hypothesis from the list of hypotheses to test\n        pi[idx] = np.inf\n        d, di[idx] = di[idx], 0\n        lambda_indexes.append(idx)\n\n        # Adjust the significance levels for the remaining hypotheses\n        neighbors = get_neighbors(idx, param_shape, di)\n        if neighbors:\n            for neighbor in neighbors:\n                di[neighbor] += d / len(neighbors)\n        else:\n            di[np.argmin(pi)] += d\n\n        # Find the new index of the smallest p-value\n        idx = np.argmin(pi)\n        np.testing.assert_approx_equal(delta, np.sum(di))\n\n    # Convert the list of rejected indices to a numpy array\n    lambda_indexes = np.array(lambda_indexes)\n    return lambda_indexes\n</code></pre>"},{"location":"api/tools/fwer_control/#tools.fwer_control.get_neighbors","title":"get_neighbors","text":"<pre><code>get_neighbors(index, shape, di)\n</code></pre> <p>Get the neighbors of a given index in an n-dimensional array.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>The index of the hypothesis (1D array).</p> required <code>shape</code> <code>tuple</code> <p>The shape of the n-dimensional array.</p> required <code>di</code> <code>ndarray</code> <p>The significance levels (1D array).</p> required <p>Returns:</p> Name Type Description <code>neighbors</code> <code>list</code> <p>List of indices (1D) of the neighboring hypotheses.</p> Source code in <code>risk_control/tools/fwer_control.py</code> <pre><code>def get_neighbors(index: tuple, shape: tuple, di: np.ndarray) -&gt; list:\n    \"\"\"\n    Get the neighbors of a given index in an n-dimensional array.\n\n    Parameters\n    ----------\n    index : int\n        The index of the hypothesis (1D array).\n    shape : tuple\n        The shape of the n-dimensional array.\n    di : np.ndarray\n        The significance levels (1D array).\n\n    Returns\n    -------\n    neighbors : list\n        List of indices (1D) of the neighboring hypotheses.\n    \"\"\"\n    index = np.unravel_index(index, shape)\n    neighbors = []\n    for dim in range(len(shape)):\n        for offset in [-1, 1]:\n            neighbor = list(index)\n            neighbor[dim] += offset\n            if 0 &lt;= neighbor[dim] &lt; shape[dim]:\n                neighbor = np.ravel_multi_index(neighbor, shape)\n                if not (0 &lt;= neighbor &lt; len(di)):\n                    raise ValueError(\n                        f\"Invalid neighbor index: {neighbor} when shape is {shape}, di.shape is {len(di)}\"\n                    )\n                if di[neighbor] != 0:\n                    neighbors.append(neighbor)\n    return neighbors\n</code></pre>"},{"location":"api/tools/pvalues/","title":"P-Values","text":""},{"location":"api/tools/pvalues/#tools.pvalues","title":"P-Values Utilities","text":"<p>Functions:</p> Name Description <code>compute_clt_p_values</code> <p>Compute p-values using the Central Limit Theorem (CLT) inequality.</p> <code>compute_hb_p_values</code> <p>Compute Hoeffding-Bentkus inequality for given risk values.</p>"},{"location":"api/tools/pvalues/#tools.pvalues.compute_clt_p_values","title":"compute_clt_p_values","text":"<pre><code>compute_clt_p_values(risk_values, alpha, n_samples)\n</code></pre> <p>Compute p-values using the Central Limit Theorem (CLT) inequality.</p> <p>Parameters:</p> Name Type Description Default <code>risk_values</code> <code>ndarray</code> <p>Array of risk values.</p> required <code>alpha</code> <code>float</code> <p>Threshold value for risk.</p> required <code>n_samples</code> <code>int</code> <p>Number of samples used to compute risk values.</p> required <p>Returns:</p> Name Type Description <code>clt_p_values</code> <code>ndarray</code> <p>Array of p-values computed using the CLT inequality.</p> Source code in <code>risk_control/tools/pvalues.py</code> <pre><code>def compute_clt_p_values(\n    risk_values: np.ndarray, alpha: float, n_samples: int\n) -&gt; np.ndarray:\n    \"\"\"\n    Compute p-values using the Central Limit Theorem (CLT) inequality.\n\n    Parameters\n    ----------\n    risk_values : np.ndarray\n        Array of risk values.\n    alpha : float\n        Threshold value for risk.\n    n_samples : int\n        Number of samples used to compute risk values.\n\n    Returns\n    -------\n    clt_p_values : np.ndarray\n        Array of p-values computed using the CLT inequality.\n    \"\"\"\n    means = np.nanmean(risk_values, axis=-1)\n    stds = np.nanstd(risk_values, axis=-1)\n\n    clt_p_values = 1 - norm.cdf((alpha - means) / stds * np.sqrt(n_samples))\n\n    return clt_p_values\n</code></pre>"},{"location":"api/tools/pvalues/#tools.pvalues.compute_hb_p_values","title":"compute_hb_p_values","text":"<pre><code>compute_hb_p_values(risk_values, alpha, n_samples)\n</code></pre> <p>Compute Hoeffding-Bentkus inequality for given risk values.</p> <p>Parameters:</p> Name Type Description Default <code>risk_values</code> <code>ndarray</code> <p>Array of risk values.</p> required <code>alpha</code> <code>float</code> <p>Threshold value for risk.</p> required <code>n_samples</code> <code>int</code> <p>Number of samples used to compute risk values.</p> required <p>Returns:</p> Name Type Description <code>hb_p_values</code> <code>ndarray</code> <p>Array of p-values computed using the Hoeffding-Bentkus inequality.</p> Source code in <code>risk_control/tools/pvalues.py</code> <pre><code>def compute_hb_p_values(\n    risk_values: np.ndarray, alpha: float, n_samples: int\n) -&gt; np.ndarray:\n    \"\"\"\n    Compute Hoeffding-Bentkus inequality for given risk values.\n\n    Parameters\n    ----------\n    risk_values : np.ndarray\n        Array of risk values.\n    alpha : float\n        Threshold value for risk.\n    n_samples : int\n        Number of samples used to compute risk values.\n\n    Returns\n    -------\n    hb_p_values : np.ndarray\n        Array of p-values computed using the Hoeffding-Bentkus inequality.\n    \"\"\"\n    n = n_samples\n    risks = np.nanmean(risk_values, axis=-1)\n\n    def _h(r: float, a: float) -&gt; float:\n        \"\"\"\n        Helper function to compute Hoeffding's function.\n\n        Parameters\n        ----------\n        r : float\n            Risk value.\n        a : float\n            Significance level.\n\n        Returns\n        -------\n        h : float\n            Hoeffding's function value.\n        \"\"\"\n        elt1 = r * np.log(r / a)\n        elt2 = (1 - r) * np.log((1 - r) / (1 - a))\n        return np.nan_to_num(elt1 + elt2)\n\n    hoeffding_p_values = np.exp(-n * _h(np.minimum(risks, alpha), alpha))\n    bentkus_p_values = np.e * binom.cdf(np.ceil(n * risks), n, alpha)\n    hb_p_values = np.minimum(hoeffding_p_values, bentkus_p_values)\n\n    return hb_p_values\n</code></pre>"},{"location":"generated/gallery/","title":"Tutorial","text":"<p> Selective Classification </p> <p> Multi-Selective Classification </p> <p> Selective Regression </p> <p> Download all examples in Python source code: gallery_python.zip</p> <p> Download all examples in Jupyter notebooks: gallery_jupyter.zip</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/mg_execution_times/","title":"Computation times","text":"<p>00:02.231 total execution time for generated_gallery files:</p> <p>+-----------------------------------------------------------------------------------------------+-----------+--------+ | plot_classification (examples/plot_classification.py)             | 00:01.052 | 0.0 MB | +-----------------------------------------------------------------------------------------------+-----------+--------+ | plot_regression (examples/plot_regression.py)                         | 00:01.024 | 0.0 MB | +-----------------------------------------------------------------------------------------------+-----------+--------+ | plot_classification_bis (examples/plot_classification_bis.py) | 00:00.155 | 0.0 MB | +-----------------------------------------------------------------------------------------------+-----------+--------+</p>"},{"location":"generated/gallery/plot_classification/","title":"Selective Classification","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/plot_classification/#selective-classification","title":"Selective Classification","text":"<p>This example shows how to use the <code>SelectiveClassification</code> and <code>MapieRiskControl</code> classes to perform selective classification.</p> <pre><code>import os\nimport sys\n\nfrom risk_control.decision.base import BaseDecision\nfrom risk_control.parameter import BaseParameterSpace\n\nbasedir = os.path.abspath(os.path.join(os.path.curdir, \"..\"))\nsys.path.append(basedir)\nbasedir = os.path.abspath(os.path.join(os.path.curdir, \".\"))\nsys.path.append(basedir)\n\nimport numpy as np\nfrom risk_control import MapieRiskControl\nfrom risk_control.decision import SelectiveClassification\nfrom risk_control.plot import plot_p_values, plot_risk_curve\nfrom risk_control.risk import AccuracyRisk, BaseRisk, CoverageRisk, RatioPredictionRisk\nfrom utils.data import get_data_classification\nfrom utils.model import get_model_classification\n\nrandom_state = 42\nnp.random.seed(42)\n</code></pre> <p>First, we load the data and train a model.</p> <pre><code>X_train, X_cal, X_test, y_train, y_cal, y_test = get_data_classification(random_state)\nclf = get_model_classification(X_train, y_train)\n</code></pre> <p>We can plot the data and the decision boundary.</p> <pre><code># plot_classification(X_train, y_train)\n</code></pre> <p>Here, we define the decision, the risks, and the parameter space.</p> <p>We use the <code>SelectiveClassification</code> decision, the <code>AccuracyRisk</code>, <code>RatioPredictionRisk</code> and <code>CoverageRisk</code> risks.</p> <ul> <li>The <code>SelectiveClassification</code> decision is a selective classification decision. In practice, it is a classification model with a threshold on the best class confidence score. If the confidence score is above the threshold, the prediction is accepted, otherwise it is rejected. The threshold is the parameter to tune.</li> <li>The <code>AccuracyRisk</code> risk is the accuracy risk. We want the accuracy to be controlled at a given level (here 0.2, TODO: report the target performance instead of the target risk).</li> <li>The <code>RatioPredictionRisk</code> risk is the ratio prediction risk. It is the ratio of accepted predictions. We want the ratio of predictions to be controlled at a given level (here 0.3, TODO: report the target performance instead of the target risk).</li> <li>The <code>CoverageRisk</code> risk is the coverage risk. It is the ratio of predictions containing the true label. We want the coverage to be controlled at a given level (here 0.5, TODO: report the target performance instead of the target risk).</li> </ul> <p>We want to find the valid thresholds that control the risks at the given levels with a confidence level (here 0.9, TODO: report the confidence level instead of the delta).</p> <p>Among the valid thresholds, we want to find the one that maximizes the <code>AccuracyRisk</code> risk (beause it is the first risk in the list of risks and <code>control_method=\"lmin\"</code>).</p> <pre><code>parameter_range = np.arange(-1.0, 5.0, 0.1)\n\ndecision: BaseDecision = SelectiveClassification(estimator=clf)\nrisks: list[BaseRisk] = [AccuracyRisk(0.2), RatioPredictionRisk(0.3), CoverageRisk(0.5)]\nparams: BaseParameterSpace = {\"threshold\": parameter_range}  # , \"toto\": parameter_range}\n\nclf_mapie = MapieRiskControl(\n    decision=decision,\n    risks=risks,\n    params=params,\n    delta=0.1,\n    control_method=\"lmin\",\n)\n</code></pre> <p>Now, we fit the model and plot the results. In practice, this function will be used to find the valid thresholds that control the risks at the given levels with a confidence level given by the data.</p> <p>A summary of the results is printed that contains the optimal threshold and the corresponding risks.</p> <pre><code>clf_mapie.fit(X_cal, y_cal)\nclf_mapie.summary()\n</code></pre> <p>Out:</p> <pre><code>/Users/thibaultcordier/VSCodeProjects/mapie-experiments/RiskControl/risk_control/tools/pvalues.py:28: RuntimeWarning: divide by zero encountered in divide\n  clt_p_values = 1 - norm.cdf((alpha - means) / stds * np.sqrt(n_samples))\n=== SUMMARY ===\np(risk&lt;=alpha) &gt;= 1-delta\n1-delta: 0.90\n=== risks ===\naccuracy        | optimal: 0.82 | alpha: 0.8\npred_ratio      | optimal: 0.79 | alpha: 0.7\ncoverage        | optimal: 0.65 | alpha: 0.5\n=== params ===\nthreshold       | optimal: 0.90\n</code></pre> <p>We can plot the risk curves for each risk.</p> <pre><code>plot_risk_curve(clf_mapie)\n</code></pre> <p></p> <p>Out:</p> <pre><code>/Users/thibaultcordier/VSCodeProjects/mapie-experiments/RiskControl/risk_control/plot.py:144: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n  plt.show()\n</code></pre> <p>We can also plot the p-values for each multiple tests (parameter space).</p> <pre><code>plot_p_values(clf_mapie)\n</code></pre> <p></p> <p>Out:</p> <pre><code>/Users/thibaultcordier/VSCodeProjects/mapie-experiments/RiskControl/risk_control/plot.py:30: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n  plt.show()\n</code></pre> <p>Finally, we can use the optimal threshold to predict on the test set and compute the risks. The risks are computed on the test set and converted to performance metrics. We can check that the risks are controlled at the given levels.</p> <pre><code>y_pred = clf_mapie.predict(X_test)\nfor risk in risks:\n    ratio = risk.convert_to_performance(np.nanmean(risk.compute(y_pred, y_test)))\n    print(f\"{risk.name}: {ratio:.2f}\")\n</code></pre> <p>Out:</p> <pre><code>accuracy: 0.80\npred_ratio: 0.77\ncoverage: 0.62\n</code></pre> <p>Total running time of the script: ( 0 minutes  1.052 seconds)</p> <p> Download Python source code: plot_classification.py</p> <p> Download Jupyter notebook: plot_classification.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/plot_classification_bis/","title":"Multi-Selective Classification","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/plot_classification_bis/#multi-selective-classification","title":"Multi-Selective Classification","text":"<p>This example shows how to use the <code>MultiSelectiveClassification</code> and <code>MapieRiskControl</code> classes to perform multi-selective classification.</p> <pre><code>import os\nimport sys\n\nfrom risk_control.decision.base import BaseDecision\nfrom risk_control.parameter import BaseParameterSpace\n\nbasedir = os.path.abspath(os.path.join(os.path.curdir, \"..\"))\nsys.path.append(basedir)\nbasedir = os.path.abspath(os.path.join(os.path.curdir, \".\"))\nsys.path.append(basedir)\n\nimport numpy as np\nfrom risk_control import MapieRiskControl\nfrom risk_control.decision import MultiSelectiveClassification\nfrom risk_control.plot import plot_p_values, plot_risk_curve\nfrom risk_control.risk import AccuracyRisk, BaseRisk, CoverageRisk, RatioPredictionRisk\nfrom utils.data import get_data_classification\nfrom utils.model import get_model_classification\n\nrandom_state = 42\nnp.random.seed(42)\n</code></pre> <p>First, we load the data and train a model.</p> <pre><code>X_train, X_cal, X_test, y_train, y_cal, y_test = get_data_classification(random_state)\nclf = get_model_classification(X_train, y_train)\n</code></pre> <p>We can plot the data and the decision boundary.</p> <pre><code># plot_classification(X_train, y_train)\n</code></pre> <p>Here, we define the decision, the risks, and the parameter space.</p> <p>We use the <code>MultiSelectiveClassification</code> decision, the <code>AccuracyRisk</code>, <code>RatioPredictionRisk</code> and <code>CoverageRisk</code> risks.</p> <ul> <li>The <code>MultiSelectiveClassification</code> decision is a selective classification decision. In practice, it is a classification model with a threshold on any class confidence score. If the class confidence score is above the threshold, the class is put in the prediction set, otherwise it is not. The threshold is the parameter to tune.</li> <li>The <code>AccuracyRisk</code> risk is the accuracy risk. We want the accuracy to be controlled at a given level (here 0.2, TODO: report the target performance instead of the target risk).</li> <li>The <code>RatioPredictionRisk</code> risk is the ratio prediction risk. It is the ratio of accepted predictions. We want the ratio of predictions to be controlled at a given level (here 0.3, TODO: report the target performance instead of the target risk).</li> <li>The <code>CoverageRisk</code> risk is the coverage risk. It is the ratio of predictions containing the true label. We want the coverage to be controlled at a given level (here 0.5, TODO: report the target performance instead of the target risk).</li> </ul> <p>We want to find the valid thresholds that control the risks at the given levels with a confidence level (here 0.9, TODO: report the confidence level instead of the delta).</p> <p>Among the valid thresholds, we want to find the one that maximizes the <code>AccuracyRisk</code> risk (beause it is the first risk in the list of risks and <code>control_method=\"lmin\"</code>).</p> <pre><code>parameter_range = np.arange(-1.0, 5.0, 0.1)\n\ndecision: BaseDecision = MultiSelectiveClassification(estimator=clf)\nrisks: list[BaseRisk] = [AccuracyRisk(0.2), RatioPredictionRisk(0.3), CoverageRisk(0.5)]\nparams: BaseParameterSpace = {\"threshold\": parameter_range}  # , \"toto\": parameter_range}\n\nclf_mapie = MapieRiskControl(\n    decision=decision,\n    risks=risks,\n    params=params,\n    delta=0.1,\n    control_method=\"lmin\",\n)\n</code></pre> <p>Now, we fit the model and plot the results. In practice, this function will be used to find the valid thresholds that control the risks at the given levels with a confidence level given by the data.</p> <p>A summary of the results is printed that contains the optimal threshold and the corresponding risks.</p> <pre><code>clf_mapie.fit(X_cal, y_cal)\nclf_mapie.summary()\n</code></pre> <p>Out:</p> <pre><code>/Users/thibaultcordier/VSCodeProjects/mapie-experiments/RiskControl/risk_control/tools/pvalues.py:28: RuntimeWarning: divide by zero encountered in divide\n  clt_p_values = 1 - norm.cdf((alpha - means) / stds * np.sqrt(n_samples))\n/Users/thibaultcordier/VSCodeProjects/mapie-experiments/RiskControl/risk_control/risk_control.py:425: UserWarning: No valid hypotheses.\n  warnings.warn(\"No valid hypotheses.\")\n=== SUMMARY ===\np(risk&lt;=alpha) &gt;= 1-delta\n1-delta: 0.90\n=== risks ===\naccuracy        | optimal: inf  | alpha: 0.8\npred_ratio      | optimal: inf  | alpha: 0.7\ncoverage        | optimal: inf  | alpha: 0.5\n=== params ===\nthreshold       | optimal: inf\n</code></pre> <p>We can plot the risk curves for each risk.</p> <pre><code>plot_risk_curve(clf_mapie)\n</code></pre> <p></p> <p>Out:</p> <pre><code>/Users/thibaultcordier/VSCodeProjects/mapie-experiments/RiskControl/risk_control/plot.py:144: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n  plt.show()\n</code></pre> <p>We can also plot the p-values for each multiple tests (parameter space).</p> <pre><code>plot_p_values(clf_mapie)\n</code></pre> <p></p> <p>Out:</p> <pre><code>/Users/thibaultcordier/VSCodeProjects/mapie-experiments/RiskControl/risk_control/plot.py:30: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n  plt.show()\n</code></pre> <p>Finally, we can use the optimal threshold to predict on the test set and compute the risks. The risks are computed on the test set and converted to performance metrics. We can check that the risks are controlled at the given levels.</p> <pre><code>y_pred = clf_mapie.predict(X_test)\nfor risk in risks:\n    ratio = risk.convert_to_performance(np.nanmean(risk.compute(y_pred, y_test)))\n    print(f\"{risk.name}: {ratio:.2f}\")\n</code></pre> <p>Out:</p> <pre><code>accuracy: 0.65\npred_ratio: 1.00\ncoverage: 0.89\n</code></pre> <p>Total running time of the script: ( 0 minutes  0.155 seconds)</p> <p> Download Python source code: plot_classification_bis.py</p> <p> Download Jupyter notebook: plot_classification_bis.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/plot_regression/","title":"Selective Regression","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/plot_regression/#selective-regression","title":"Selective Regression","text":"<p>This example shows how to use the <code>SelectiveRegression</code> and <code>MapieRiskControl</code> classes to perform selective regression.</p> <pre><code>import os\nimport sys\n\nfrom risk_control.decision.base import BaseDecision\nfrom risk_control.parameter import BaseParameterSpace\n\nbasedir = os.path.abspath(os.path.join(os.path.curdir, \"..\"))\nsys.path.append(basedir)\nbasedir = os.path.abspath(os.path.join(os.path.curdir, \".\"))\nsys.path.append(basedir)\n\nimport numpy as np\nfrom risk_control import MapieRiskControl\nfrom risk_control.decision import SelectiveRegression\nfrom risk_control.plot import plot_p_values, plot_risk_curve\nfrom risk_control.risk import BaseRisk, MSERisk, RatioPredictionRisk\nfrom utils.data import get_data_regression\nfrom utils.model import get_model_regression\n\nrandom_state = 42\nnp.random.seed(42)\n</code></pre> <p>First, we load the data and train a model.</p> <pre><code>mse_max = 20.0\n\nX_train, X_cal, X_test, y_train, y_cal, y_test = get_data_regression(random_state)\nclf, res = get_model_regression(X_train, y_train, X_cal, y_cal)\n\nprint(f\"Mean MSE: {np.nanmean((clf.predict(X_test) - y_test)**2):.2f}\")\n</code></pre> <p>Out:</p> <pre><code>Mean MSE: 0.68\n</code></pre> <p>Here, we define the decision, the risks, and the parameter space.</p> <p>We use the <code>SelectiveRegression</code> decision, the <code>MSERisk</code> and <code>RatioPredictionRisk</code> risks.</p> <ul> <li>The <code>SelectiveRegression</code> decision is a selective regression decision. In practice, it is a  regression model with a threshold on the residual. If the residual is below the threshold, the prediction is accepted, otherwise it is rejected. The threshold is the parameter to tune.</li> <li>The <code>MSERisk</code> risk is the mean squared error risk. We want the mean squared error to be controlled at a given level (here 0.3, TODO: report the target performance instead of the target risk).</li> <li>The <code>RatioPredictionRisk</code> risk is the ratio prediction risk. It is the ratio of accepted predictions. We want the ratio of predictions to be controlled at a given level (here 0.2, TODO: report the target performance instead of the target risk).</li> </ul> <p>We want to find the valid thresholds that control the risks at the given levels with a confidence level (here 0.9, TODO: report the confidence level instead of the delta).</p> <p>Among the valid thresholds, we want to find the one that minimizes the mean squared error (beause it is the first risk in the list of risks and <code>control_method=\"lmin\"</code>).</p> <pre><code>parameter_range = np.linspace(0.05, 5.0, 100)\n\ndecision: BaseDecision = SelectiveRegression(estimator=clf, residual=res)\nrisks: list[BaseRisk] = [MSERisk(0.6, mse_max=mse_max), RatioPredictionRisk(0.2)]\nparams: BaseParameterSpace = {\"threshold\": parameter_range}\n\nclf_mapie = MapieRiskControl(\n    decision=decision,\n    risks=risks,\n    params=params,\n    delta=0.1,\n    control_method=\"lmin\",\n)\n</code></pre> <p>Now, we fit the model and plot the results. In practice, this function will be used to find the valid thresholds that control the risks at the given levels with a confidence level given by the data.</p> <p>A summary of the results is printed that contains the optimal threshold and the corresponding risks.</p> <pre><code>clf_mapie.fit(X_cal, y_cal)\nclf_mapie.summary()\n</code></pre> <p>Out:</p> <pre><code>=== SUMMARY ===\np(risk&lt;=alpha) &gt;= 1-delta\n1-delta: 0.90\n=== risks ===\nmse     | optimal: 0.53 | alpha: 0.6\npred_ratio      | optimal: 0.83 | alpha: 0.8\n=== params ===\nthreshold       | optimal: 0.90\n</code></pre> <p>We can plot the risk curves for each risk.</p> <pre><code>plot_risk_curve(clf_mapie)\n</code></pre> <p></p> <p>Out:</p> <pre><code>/Users/thibaultcordier/VSCodeProjects/mapie-experiments/RiskControl/risk_control/plot.py:144: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n  plt.show()\n</code></pre> <p>We can also plot the p-values for each multiple tests (parameter space).</p> <pre><code>plot_p_values(clf_mapie)\n</code></pre> <p></p> <p>Out:</p> <pre><code>/Users/thibaultcordier/VSCodeProjects/mapie-experiments/RiskControl/risk_control/plot.py:30: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n  plt.show()\n</code></pre> <p>Finally, we can use the optimal threshold to predict on the test set and compute the risks. The risks are computed on the test set and converted to performance metrics. We can check that the risks are controlled at the given levels.</p> <pre><code>y_pred = clf_mapie.predict(X_test)\nfor risk in risks:\n    ratio = risk.convert_to_performance(np.nanmean(risk.compute(y_pred, y_test)))\n    print(f\"{risk.name}: {ratio:.2f}\")\n\nprint(MSERisk(mse_max)._compute_from_predictions(clf_mapie.predict(X_test), y_test))\nprint(MSERisk(mse_max)._compute_from_estimator(clf_mapie, X_test, y_test))\n</code></pre> <p>Out:</p> <pre><code>mse: 0.55\npred_ratio: 0.84\n0.3096934191981804\n0.3096934191981804\n</code></pre> <p>Total running time of the script: ( 0 minutes  1.024 seconds)</p> <p> Download Python source code: plot_regression.py</p> <p> Download Jupyter notebook: plot_regression.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"}]}